{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3525c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cohere\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "\n",
    "# -------------------------------\n",
    "# RAG Agent: Retrieval & LLM\n",
    "# -------------------------------\n",
    "# --------------------------\n",
    "# Embedding Helpers\n",
    "# --------------------------\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "def load_indices(\n",
    "    text_index_path: str = os.path.join(data_dir, \"faiss_text.index\"),\n",
    "    image_index_path: str = os.path.join(data_dir, \"faiss_image.index\"),\n",
    "    text_meta_path: str = os.path.join(data_dir, \"text_docs_info.pkl\"),\n",
    "    image_meta_path: str = os.path.join(data_dir, \"image_docs_info.pkl\"),\n",
    "):\n",
    "    \"\"\"Return (idx_text, text_meta, idx_img, image_meta).\"\"\"\n",
    "    idx_text, text_meta = None, []\n",
    "    idx_img, image_meta = None, []\n",
    "\n",
    "    if os.path.exists(text_index_path) and os.path.exists(text_meta_path):\n",
    "        idx_text = faiss.read_index(text_index_path)\n",
    "        with open(text_meta_path, \"rb\") as f:\n",
    "            text_meta = pickle.load(f)\n",
    "\n",
    "    if os.path.exists(image_index_path) and os.path.exists(image_meta_path):\n",
    "        idx_img = faiss.read_index(image_index_path)\n",
    "        with open(image_meta_path, \"rb\") as f:\n",
    "            image_meta = pickle.load(f)\n",
    "\n",
    "    return idx_text, text_meta, idx_img, image_meta\n",
    "\n",
    "co_client = cohere.ClientV2(api_key=\"SJcDVJBzLECN6S8mAT0SGbzx6PMUtFoyvHVQ5Kt0\")\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def l2_normalize(vec: np.ndarray) -> np.ndarray:\n",
    "    norm = np.linalg.norm(vec)\n",
    "    return vec / norm if norm > 0 else vec\n",
    "\n",
    "\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get a normalized text embedding via Cohere embed-v4.0\n",
    "    \"\"\"\n",
    "    resp = co_client.embed(\n",
    "        model=\"embed-v4.0\",\n",
    "        input_type=\"search_document\",\n",
    "        embedding_types=[\"float\"],\n",
    "        texts=[text],\n",
    "    )\n",
    "    vec = np.array(resp.embeddings.float[0], dtype=np.float32)\n",
    "    return l2_normalize(vec)\n",
    "\n",
    "class RagAgent:\n",
    "    \"\"\"\n",
    "    RAG Agent that handles multimodal retrieval (text + image) from separate FAISS indices,\n",
    "    and can query Gemini for direct answers via the google-genai client.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        text_index_path: str = os.path.join(\"data\", \"faiss_text.index\"),\n",
    "        image_index_path: str = os.path.join(\"data\", \"faiss_image.index\"),\n",
    "        text_meta_path: str = os.path.join(\"data\", \"text_docs_info.pkl\"),\n",
    "        image_meta_path: str = os.path.join(\"data\", \"image_docs_info.pkl\"),\n",
    "    ) -> None:\n",
    "        # Load FAISS indices and metadata\n",
    "        self.idx_text, self.text_meta, self.idx_img, self.image_meta = load_indices(\n",
    "            text_index_path, image_index_path, text_meta_path, image_meta_path\n",
    "        )\n",
    "\n",
    "        # Cohere client for embeddings\n",
    "        self.co_client = cohere.ClientV2(api_key=\"SJcDVJBzLECN6S8mAT0SGbzx6PMUtFoyvHVQ5Kt0\")\n",
    "\n",
    "        # google-genai client for LLM generation\n",
    "        self.genai_client = genai.Client(api_key=\"AIzaSyDoElOZE1wayqlHYGaTNh_uAc2QRgjs85Q\")\n",
    "\n",
    "    def embed_query(self, query: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Embed the user query into the shared vector space.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            resp = self.co_client.embed(\n",
    "                model=\"embed-v4.0\",\n",
    "                input_type=\"search_query\",\n",
    "                embedding_types=[\"float\"],\n",
    "                texts=[query],\n",
    "            )\n",
    "            vec = np.array(resp.embeddings.float[0], dtype=np.float32)\n",
    "            return l2_normalize(vec)\n",
    "        except Exception as e:\n",
    "            print(f\"Query embedding error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def retrieve(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k_text: int = 5,\n",
    "        top_k_image: int = 5,\n",
    "        top_n: int = 3,\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform multimodal retrieval: query both text and image FAISS indices,\n",
    "        fuse and re-rank results, and return top_n entries.\n",
    "\n",
    "        Each hit dict contains: doc_id, source, modality, chunk/page, score, content/preview.\n",
    "        \"\"\"\n",
    "        q_vec = self.embed_query(query)\n",
    "        if q_vec is None:\n",
    "            return []\n",
    "\n",
    "        all_hits: List[Dict[str, Any]] = []\n",
    "        # --- Text retrieval ---\n",
    "        if self.idx_text:\n",
    "            D_t, I_t = self.idx_text.search(np.array([q_vec]), top_k_text)\n",
    "            for score, idx in zip(D_t[0], I_t[0]):\n",
    "                if idx < len(self.text_meta):\n",
    "                    meta = self.text_meta[idx]\n",
    "                    all_hits.append({\n",
    "                        \"doc_id\": meta[\"doc_id\"],\n",
    "                        \"source\": meta[\"source\"],\n",
    "                        \"modality\": \"text\",\n",
    "                        \"chunk\": meta.get(\"chunk\"),\n",
    "                        \"score\": float(score),\n",
    "                        \"content\": meta.get(\"content\"),\n",
    "                    })\n",
    "        # --- Image retrieval ---\n",
    "        if self.idx_img:\n",
    "            D_i, I_i = self.idx_img.search(np.array([q_vec]), top_k_image)\n",
    "            for score, idx in zip(D_i[0], I_i[0]):\n",
    "                if idx < len(self.image_meta):\n",
    "                    meta = self.image_meta[idx]\n",
    "                    all_hits.append({\n",
    "                        \"doc_id\": meta[\"doc_id\"],\n",
    "                        \"source\": meta[\"source\"],\n",
    "                        \"modality\": \"image\",\n",
    "                        \"page\": meta.get(\"page\"),\n",
    "                        \"score\": float(score),\n",
    "                        \"preview\": meta.get(\"preview_image\"),\n",
    "                    })\n",
    "        # --- Fuse & re-rank ---\n",
    "        sorted_hits = sorted(all_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "        return sorted_hits[:top_n]\n",
    "\n",
    "    def generate_answer(\n",
    "        self,\n",
    "        question: str,\n",
    "        context: Dict[str, Any],\n",
    "        use_image: bool = False,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Use google-genai to generate an answer given either text content or an image preview.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if use_image and context.get(\"preview\"):\n",
    "                img = Image.open(context[\"preview\"])\n",
    "                prompt = [\n",
    "                    f\"Answer the question based on the following image.\\nDon't use markdown.\\nPlease provide enough context.\\n\\nQuestion: {question}\",\n",
    "                    img,\n",
    "                ]\n",
    "                response = self.genai_client.models.generate_content(\n",
    "                    model=\"gemini-2.5-flash\",\n",
    "                    contents=prompt\n",
    "                )\n",
    "            else:\n",
    "                text = context.get(\"content\", \"\")\n",
    "                prompt = [\n",
    "                    f\"Answer the question based on the following information.\\nDon't use markdown.\\nPlease provide enough context.\\n\\nInformation: {text}\\nQuestion: {question}\"\n",
    "                ]\n",
    "                response = self.genai_client.models.generate_content(\n",
    "                    model=\"gemini-2.5-flash\",\n",
    "                    contents=[prompt[0]]  # Pass a list of one string\n",
    "                )\n",
    "            if response.text is not None:\n",
    "                return response.text.strip()\n",
    "            else:\n",
    "                return \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"Gemini generation error: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "def rag_tool(query, top_k_text=5, top_k_image=5, top_n=3):\n",
    "    agent = RagAgent()\n",
    "    hits = agent.retrieve(query, top_k_text=top_k_text, top_k_image=top_k_image, top_n=top_n)\n",
    "    for h in hits:\n",
    "        modality = h['modality'].upper()\n",
    "        print(f\"[{modality}] {h['score']:.3f} â€” {h['source']} (ID: {h['doc_id']})\")\n",
    "    concat_ans= []\n",
    "    for h in hits:\n",
    "        ans = agent.generate_answer(query,\n",
    "                                    h,\n",
    "                                    use_image=(h['modality']=='image')\n",
    "                                    )\n",
    "        concat_ans.append(ans)\n",
    "\n",
    "    return concat_ans\n",
    "        \n",
    "def aggregator(query, concat_ans):\n",
    "    msg = [\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":f\"\"\"you are a helpful assistant who can decide and select the right answer among \n",
    "            multiple answers for the given question.\n",
    "            here is the question: {query} \\n\\n\n",
    "            candidate answers: {concat_ans} \\n\n",
    "\n",
    "            - If you find that more than one answer is correct and complement to each other,combine them\n",
    "            into one coherent and well organized answer.\n",
    "\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages= msg,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    final_ans= res.choices[0].message.content\n",
    "    return final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a10f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AnyMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,    \n",
    ")\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Union, Literal\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant as LCQdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qdrant_models\n",
    "from pymongo import MongoClient\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ---------------------------\n",
    "# Memory Configuration\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class MemoryConfig:\n",
    "    # Qdrant settings (for long-term vector memory)\n",
    "    qdrant_url: str = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "    qdrant_api_key: Optional[str] = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "    # MongoDB settings (for structured facts & message history)\n",
    "    mongo_uri: str = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "    db_name: str = os.getenv(\"MONGO_DB\", \"agentic_memory\")\n",
    "\n",
    "    # Short-term buffer size (user+assistant turns)\n",
    "    short_term_window: int = int(os.getenv(\"SHORT_TERM_WINDOW\", \"6\"))\n",
    "\n",
    "    # Embeddings model for long-term memory\n",
    "    embeddings: OpenAIEmbeddings = field(\n",
    "        default_factory=lambda: OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    )\n",
    "\n",
    "# ---------------------------\n",
    "# Memory Agent\n",
    "# ---------------------------\n",
    "class MemoryAgent:\n",
    "    \"\"\"\n",
    "    Agentic memory manager handling:\n",
    "      - Short-term conversational context (in-memory)\n",
    "      - Long-term semantic memory (Qdrant)\n",
    "      - Structured user facts (MongoDB using LLM extraction)\n",
    "      - Persistent message history for UI pagination (MongoDB)\n",
    "\n",
    "    Uses OpenAI text-embedding-3-small for long-term embeddings and GPT-4o Mini to extract facts.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_id: str,\n",
    "        thread_id: str,\n",
    "        cfg: Optional[MemoryConfig] = None,\n",
    "    ) -> None:\n",
    "        self.user_id = str(user_id)\n",
    "        self.thread_id = str(thread_id)\n",
    "        self.cfg = cfg or MemoryConfig()\n",
    "\n",
    "        # ----- Qdrant long-term memory -----\n",
    "        self.qdrant_client = QdrantClient(\n",
    "            url=self.cfg.qdrant_url,\n",
    "            api_key=self.cfg.qdrant_api_key\n",
    "        )\n",
    "      \n",
    "        self.collection_name = f\"mem_{self.user_id}_{self.thread_id}\"\n",
    "        self._ensure_qdrant_collection()\n",
    "        self.qdrant_store = LCQdrant(\n",
    "            client=self.qdrant_client,\n",
    "            collection_name=self.collection_name,\n",
    "            embeddings=self.cfg.embeddings,\n",
    "        )\n",
    "\n",
    "        # ----- MongoDB structured facts & history -----\n",
    "        self.mongo = MongoClient(self.cfg.mongo_uri)\n",
    "        self.mongo_db = self.mongo[self.cfg.db_name]\n",
    "        self.facts_col = self.mongo_db[\"user_facts\"]\n",
    "        self.messages_col = self.mongo_db[\"messages_history\"]\n",
    "\n",
    "        # ----- In-memory short-term buffer -----\n",
    "        self._short_term: List[Dict[str, str]] = []\n",
    "\n",
    "    def _ensure_qdrant_collection(self) -> None:\n",
    "        \"\"\"Create the Qdrant collection if it does not exist.\"\"\"\n",
    "        if not self.qdrant_client.collection_exists(self.collection_name):\n",
    "            dim = len(self.cfg.embeddings.embed_query(\"test query\"))\n",
    "            self.qdrant_client.create_collection(\n",
    "                collection_name=self.collection_name,\n",
    "                vectors_config=qdrant_models.VectorParams(\n",
    "                    size=dim,\n",
    "                    distance=qdrant_models.Distance.COSINE,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def fetch_short_term(self) -> List[Dict[str,Any]]:\n",
    "        # pull the last N messages from Mongo instead of the inâ€‘memory list\n",
    "        cursor = self.messages_col.find(\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id}\n",
    "        ).sort(\"timestamp\", -1).limit(self.cfg.short_term_window * 2)\n",
    "        # reverse so oldestâ†’newest\n",
    "        return list(cursor)[::-1]\n",
    "\n",
    "\n",
    "    def fetch_history(\n",
    "        self,\n",
    "        page: int = 0,\n",
    "        page_size: int = 50\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Return paginated conversation history.\"\"\"\n",
    "        skip = page * page_size\n",
    "        cursor = self.messages_col.find(\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id}\n",
    "        ).sort(\"timestamp\", 1).skip(skip).limit(page_size)\n",
    "        return list(cursor)\n",
    "\n",
    "    def fetch_long_term(\n",
    "        self,\n",
    "        query: Optional[str] = None,\n",
    "        k: int = 5,\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Semantic recall of past conversation turns.\"\"\"\n",
    "        if query is None and self._short_term and self._short_term[-1][\"role\"] == \"user\":\n",
    "            logging.warning(\"Using last user message as query for long-term recall.\")\n",
    "            query = self._short_term[-1][\"content\"]\n",
    "        if not query:\n",
    "            return []\n",
    "        return self.qdrant_store.similarity_search(query, k=k)\n",
    "\n",
    "    def get_user_facts(self) -> Dict[str, Any]:\n",
    "        \"\"\"Retrieve the deduplicated facts dictionary for this user.\"\"\"\n",
    "        doc = self.facts_col.find_one({\"user_id\": self.user_id}) or {}\n",
    "        # 'facts' is stored as a dict; return it directly\n",
    "        return doc.get(\"facts\", {})\n",
    "\n",
    "    def update(self, user_message: str, assistant_message: str) -> None:\n",
    "        \"\"\"\n",
    "        Append new messages, persist history, long-term memory, and update facts.\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now()\n",
    "\n",
    "        # 1) Short-term buffer\n",
    "        self._short_term.append({\"role\": \"user\", \"content\": user_message})\n",
    "        self._short_term.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        excess = len(self._short_term) - (self.cfg.short_term_window * 2)\n",
    "        if excess > 0:\n",
    "            self._short_term = self._short_term[excess:]\n",
    "\n",
    "        # 2) Persist messages\n",
    "        self.messages_col.insert_many([\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id, \"role\": \"user\", \"content\": user_message, \"timestamp\": timestamp},\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id, \"role\": \"assistant\", \"content\": assistant_message, \"timestamp\": timestamp},\n",
    "        ])\n",
    "\n",
    "        # 3) Persist long-term memory\n",
    "        combined = f\"User: {user_message}\\nAssistant: {assistant_message}\"\n",
    "        doc = Document(page_content=combined, metadata={\n",
    "            \"user_id\": self.user_id,\n",
    "            \"thread_id\": self.thread_id,\n",
    "            \"timestamp\": timestamp.isoformat(),\n",
    "        })\n",
    "        self.qdrant_store.add_documents([doc])\n",
    "        print(f\"Added to long-term memory: {self.user_id} | {self.thread_id} | {timestamp}\")\n",
    "        # 4) Merge and update facts\n",
    "        existing = self.get_user_facts()  # existing dict\n",
    "        new = self.extract_facts(user_message) or {}\n",
    "        merged = {**existing, **new}\n",
    "        if merged:\n",
    "            self.facts_col.update_one(\n",
    "                {\"user_id\": self.user_id},\n",
    "                {\"$set\": {\"facts\": merged, \"last_update\": timestamp}},\n",
    "                upsert=True,\n",
    "            )\n",
    "        print(f\"Updated user facts: {self.user_id} | {self.thread_id} | {timestamp}\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_facts(text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Use an LLM (GPT-4o Mini) to extract personal/info facts from text.\n",
    "        Returns a dict of key/value pairs.\n",
    "        \"\"\"\n",
    "        prompt = (\n",
    "            \"Extract any personal profile information and relevant facts from the following text. \"\n",
    "            \"Return ONLY a JSON object with key/value pairs, no additional text, no explanations.\"\n",
    "             \"If there is no relevant information in the text, return an empty object.\\n\\n\"\n",
    "            f\"Text: {text}\"\n",
    "        )\n",
    "        try:\n",
    "            resp = openai_client.chat.completions.create(\n",
    "                model = \"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an assistant that extracts personal user information as JSON.\"},\n",
    "                    {\"role\": \"user\",   \"content\": prompt},\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            content = resp.choices[0].message.content.strip()\n",
    "            print(f\"Extracted facts: {content}\")\n",
    "            return json.loads(content)\n",
    "        except Exception as e:\n",
    "            print(f\"Fact extraction error: {e}\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Define shared State\n",
    "# ---------------------------\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    mode: str  # 'chat' or 'rag'\n",
    "    # user_profile: Optional[Dict[str, Any]]  # structured user facts/profile\n",
    "    # recent_conversation: Optional[List[Dict[str, str]]]  # short-term context\n",
    "    # relevant_past_memory: Optional[List[Document]]  # long-term semantic recalls\n",
    "\n",
    "# ---------------------------\n",
    "# Initialize Chat Agent\n",
    "# ---------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=0.5)\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=1))\n",
    "llm_with_tools = llm.bind_tools([wikipedia_tool])\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\":\n",
    "        [llm_with_tools.invoke(\n",
    "        state[\"messages\"])], \"mode\": state[\"mode\"]}\n",
    "\n",
    "# def chatbot(state: State) -> State:\n",
    "#     \"\"\"\n",
    "#     Chat agent node: normalize messages to BaseMessage, invoke LLM+tools, append assistant reply as AIMessage.\n",
    "#     \"\"\"\n",
    "#     msgs_for_llm = []\n",
    "#     for m in state.get(\"messages\", []):\n",
    "#         if isinstance(m, BaseMessage):\n",
    "#             msgs_for_llm.append(m)\n",
    "#         elif isinstance(m, dict):\n",
    "#             role = m.get(\"role\")\n",
    "#             content = m.get(\"content\", \"\")\n",
    "#             if role == \"user\":\n",
    "#                 msgs_for_llm.append(HumanMessage(content=content))\n",
    "#             elif role == \"assistant\":\n",
    "#                 msgs_for_llm.append(AIMessage(content=content))\n",
    "#             elif role == \"system\":\n",
    "#                 msgs_for_llm.append(SystemMessage(content=content))\n",
    "#     response_msg = llm_with_tools.invoke(msgs_for_llm)\n",
    "#     # Create AIMessage to ensure compatibility with tools_condition\n",
    "#     content = getattr(response_msg, 'content', str(response_msg))\n",
    "#     tool_calls = getattr(response_msg, 'tool_calls', [])\n",
    "#     assistant_msg = AIMessage(content=content, tool_calls=tool_calls)\n",
    "#     return {\"messages\": state.get(\"messages\", []) + [assistant_msg], \"mode\": state.get(\"mode\", \"chat\")}\n",
    "\n",
    "def final_response(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Process the chatbot's output before memory update, e.g., formatting or validation.\n",
    "    \"\"\"\n",
    "    last_msg = state.get(\"messages\", [])[-1]\n",
    "    content = last_msg.get(\"content\") if isinstance(last_msg, dict) else getattr(last_msg, 'content', '')\n",
    "    formatted_content = f\"Finalized response: {content}\"\n",
    "    assistant_msg = {\"role\": \"assistant\", \"content\": formatted_content}\n",
    "    return {\"messages\": state.get(\"messages\", [])[:-1] + [assistant_msg], \"mode\": state.get(\"mode\", \"chat\")}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Initialize RAG Agent\n",
    "# ---------------------------\n",
    "rag_agent = RagAgent()\n",
    "\n",
    "def rag_node(state: State) -> State:\n",
    "    \"\"\"\n",
    "    RAG agent node: retrieve, answer, and aggregate.\n",
    "    \"\"\"\n",
    "    print(f\"RAG node invoked with state: {state}\")\n",
    "    # Use last user message as query\n",
    "    last = state.get(\"messages\", [])[-1]\n",
    "    query = last.get(\"content\") if isinstance(last, dict) else getattr(last, 'content', None)\n",
    "    if query is None:\n",
    "        query = \"\"\n",
    "    hits = rag_agent.retrieve(query)\n",
    "    answers = [\n",
    "        rag_agent.generate_answer(query, hit, use_image=(hit.get(\"modality\") == \"image\"))\n",
    "        for hit in hits\n",
    "    ]\n",
    "    final = aggregator(query, answers)\n",
    "    assistant_msg = {\"role\": \"assistant\", \"content\": final}\n",
    "    return {\"messages\": state.get(\"messages\", []) + [assistant_msg], \"mode\": state.get(\"mode\", \"rag\")}  \n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Memory Agent Integration\n",
    "# ---------------------------\n",
    "memory_agent = MemoryAgent(\n",
    "    user_id=os.getenv(\"USER_ID\", \"default_user\"),\n",
    "    thread_id=os.getenv(\"THREAD_ID\", \"default_thread\")\n",
    ")\n",
    "\n",
    "\n",
    "def memory_fetch(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Fetch short-term, long-term, and structured facts; merge with incoming messages without duplication.\n",
    "    \"\"\"\n",
    "    # Only include dictionary-based incoming messages\n",
    "    incoming = [m for m in state.get(\"messages\", []) if isinstance(m, dict)]\n",
    "    # Short-term conversational context\n",
    "    short_msgs = memory_agent.fetch_short_term()\n",
    "    # Long-term semantic recalls\n",
    "    long_docs = memory_agent.fetch_long_term()\n",
    "    # Structured user facts/profile\n",
    "    facts = memory_agent.get_user_facts()\n",
    "\n",
    "    # Build system context\n",
    "    context_msgs = []\n",
    "    if facts:\n",
    "        context_msgs.append({\"role\": \"system\", \"content\": f\"User facts/profile: {facts}\"})\n",
    "    for doc in long_docs:\n",
    "        context_msgs.append({\"role\": \"system\", \"content\": f\"Memory recall: {doc.page_content}\"})\n",
    "\n",
    "    combined = context_msgs + short_msgs + incoming\n",
    "    return {\"messages\": combined, \"mode\": state.get(\"mode\", \"chat\")}\n",
    "\n",
    "def custom_tools_condition(state: Union[list[AnyMessage], dict[str, Any], BaseModel],\n",
    "    messages_key: str = \"messages\",\n",
    ") -> Literal[\"tools\", \"final_response\"]:\n",
    "    \"\"\"\n",
    "    Custom routing function to replace tools_condition, checking for tool_calls in the last message.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif isinstance(state, dict) and (messages := state.get(messages_key, [])):\n",
    "        ai_message = messages[-1]\n",
    "    elif messages := getattr(state, messages_key, []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"final_response\"\n",
    "\n",
    "def memory_update(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Update memory with the latest user and assistant messages, handling BaseMessage and dict.\n",
    "    \"\"\"\n",
    "    msgs = state[\"messages\"]\n",
    "    print(f\"Memory update invoked with messages: {msgs}\")\n",
    "    if len(msgs) >= 2:\n",
    "        # Extract user message\n",
    "        user_msg = None\n",
    "        assistant_msg = None\n",
    "        for m in reversed(msgs):\n",
    "            if isinstance(m, BaseMessage):\n",
    "                content = getattr(m, 'content', '')\n",
    "                role = getattr(m, 'role', '')\n",
    "            elif isinstance(m, dict):\n",
    "                content = m.get(\"content\", \"\")\n",
    "                role = m.get(\"role\", \"\")\n",
    "            else:\n",
    "                continue\n",
    "            if role == \"user\" and user_msg is None:\n",
    "                user_msg = content\n",
    "            elif role == \"assistant\" and assistant_msg is None:\n",
    "                assistant_msg = content\n",
    "            if user_msg and assistant_msg:\n",
    "                break\n",
    "        if user_msg and assistant_msg:\n",
    "            memory_agent.update(user_msg, assistant_msg)\n",
    "    return state\n",
    "\n",
    "# ---------------------------\n",
    "# Supervisor Node\n",
    "# ---------------------------\n",
    "# Routes based on `mode` flag in state\n",
    "# Expects 'chat' or 'rag'\n",
    "def supervisor(state: State) -> State:\n",
    "    print(f\"Supervisor invoked with state: {state}\")\n",
    "    return state\n",
    "\n",
    "# Conditional routing function for graph\n",
    "def supervisor_router(state: State):\n",
    "    mode = state.get(\"mode\", \"chat\").lower()\n",
    "    if mode == \"chat\":\n",
    "        return \"chatbot\"\n",
    "    elif mode == \"rag\":\n",
    "        return \"rag_agent\"\n",
    "    # Default fallback\n",
    "    return \"chatbot\"\n",
    "\n",
    "# ---------------------------\n",
    "# Build Graph\n",
    "# ---------------------------\n",
    "# Corrected graph construction\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"memory_fetch\", memory_fetch)\n",
    "graph_builder.add_node(\"supervisor\", supervisor)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"rag_agent\", rag_node)\n",
    "graph_builder.add_node(\"memory_update\", memory_update)\n",
    "tool_node = ToolNode(tools=[wikipedia_tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "#graph_builder.add_node(\"final_response\", final_response)\n",
    "# Conditional routing\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    supervisor_router,\n",
    "    {\n",
    "        \"chatbot\": \"chatbot\",\n",
    "        \"rag_agent\": \"rag_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    custom_tools_condition,\n",
    "    {\"tools\": \"tools\"}\n",
    ")\n",
    "# Set up edges\n",
    "graph_builder.add_edge(START, \"memory_fetch\")\n",
    "graph_builder.add_edge(\"memory_fetch\", \"supervisor\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "# Connect agents to memory update\n",
    "#graph_builder.add_edge(\"chatbot\", \"memory_update\")\n",
    "graph_builder.add_edge(\"rag_agent\", \"memory_update\")\n",
    "graph_builder.add_edge(\"chatbot\", \"memory_update\")\n",
    "graph_builder.add_edge(\"memory_update\", END)\n",
    "\n",
    "# Compile graph\n",
    "graph = graph_builder.compile()\n",
    "# ---------------------------\n",
    "# # Chat mode example\n",
    "# chat_state = {\n",
    "#     \"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is abdo, and I want to ask you a question. Who is Alan Turing?\"}],\n",
    "#     \"mode\": \"chat\"\n",
    "# }\n",
    "# try:\n",
    "#     print(\"Invoking chat agent with state: %s\", chat_state)\n",
    "#     # Cast chat_state to State type for compatibility\n",
    "#     res_chat = graph.invoke(State(chat_state))  # type: ignore\n",
    "#     print(\"Chat agent response:\", res_chat[\"messages\"][-1][\"content\"])\n",
    "# except Exception as e:\n",
    "#     print(\"Chat run error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b840376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARcAAAITCAIAAACiyM8IAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XVcFFsbB/CzHcQu3SmKgiAqKjYIdifY3d16bVGv3d3deO1uxUQRQREDSaVj2WLz/WN8ketFQGZ3Z+P5fvhjmJ2deTZ+e+bM7pwhKZVKBADAgUx0AQDoPEgRAHhBigDAC1IEAF6QIgDwghQBgBeV6AL0R+53Cb9AJuDJikUKiUhBdDkVo1BJFBrJyJTCNqWaW9PZphSiK9JVJPi+CKeUBFFiLP/rO4GDB6tYIGebUrlWNIVcB55VKo0sKJIJeXIBTyaXKhUKpVttIw9fEzMbGtGl6RhIUdWlfhQ9uZRj7cSwdGC4eRsZc3W7Yc9KKU58xy/IklLppCadLNkm0DRVFqSoiu6czCrKlzbtbGnlyCC6FhX78LIo8lJOvUBu3VZmRNeiGyBFf6wwR3p8TUrXMQ72bkyia1Gj2MeFKQnCjsPtiC5EB0CK/oyoSH52c1rfWc5UGonoWtTua5zg2bXcvjOdiS5E20GK/kBOevH1wxkD5roQXYjmfEsU3z6ROWieAT3kKoDviypNiU6uSzWoCCGE7N2ZTTtbXj3wnehCtBq0RZV1/VBGo/YWZtaGeBT47aNChULp15JLdCFaCtqiSnn/nEdjkA0zQggh3+ac59fzJGId+CqZEJCiSnlyObdJJwuiqyBSk04WTy7nEl2FloIUVezdU17dQC7L2KC/hfRpyhHyZEX5MqIL0UaQoop9iOLZu7E0ucXPnz936tSpCnc8derUokWL1FARQgiZmNMSY/lqWrlOgxRVoFikyP0usXPX6BescXFxVbvju3fvVF3LT27eRl/fCdS3ft0FKapAcrzQO4CjppUXFhauXr26S5cuLVq0GDNmzMWLFxFC27ZtW7ZsWUZGhr+//7FjxxBCjx49mj9/focOHZo3bz527NhXr15hdz9+/Hi7du3u37/fsGHDtWvXDh8+/OrVq1euXPH39//w4YPKq3WszpJKlDIJHNT9lW7/gFID8jKL6Sx1/UwhPDw8JSXlr7/+cnV1PXPmzPLly93d3cePHy+Xy2/evHn58mWEkFAonDdvXpMmTdasWWNhYbF///6pU6deuHDBzMyMTqcLhcLDhw8vXbrUy8vL2dl5yJAhLi4uS5YsUVPBcqmiIEdqaU9X0/p1FKSoAkKe3NZVXbtzr1+/Hjx4cEBAAEJo4sSJwcHB5ubmvyzDZrNPnjzJZrO5XC5CaNKkSefOnYuJiQkMDKRQKEKhcNy4cf7+/mqq8NdiTKkCngxS9AtIUQUEPJmRqbqeJT8/vyNHjhQWFjZt2rROnTpeXl5l1yAQbN269fXr1zk5Odic/Pz8klt/dy91MDKlCnlwmO5X0C+qAIlMIlPVtUe3ePHifv36PX78ePTo0SEhITt37pTJfn2Pfv/+fcSIEQqFYsWKFU+fPo2MjPxlATpdcy0DlUaC37r8F7RFFWCyyfx8KUJqOdJtamo6bNiwoUOHxsTE3L17d+/evRwOp2/fvqWXuXHjhlQqXbx4MZPJRAiVNEeE4OVJXWoZEViAdoIUVcDIlCrkydWx5oKCghs3bnTr1o3BYPj5+fn5+cXHx8fHx/93MVNTUyxCCKE7d+6oo5hKEvLkRjA8w3/AHl0FzKzpcvUMokChUHbs2DF79uy3b9/m5eVduXLlw4cPderUQQg5Ozvn5OQ8ePAgOTm5Ro0aOTk558+fl8lkkZGR0dHRHA4nIyOjzHU6OTm9f/8+KioqLy9PHTWzTSkmXAP9MWE5KIsXLya6Bq3GMqbcP5tVN1D1504zGAxfX9+bN28eOHDgyJEjaWlpo0eP7tatG4lEsrS0fP/+/cGDB7lcbmhoqEwmO378+ObNm3k83l9//YUd3c7Pz7ewsHj06NGIESPI5B+fhmZmZg8fPjx+/HijRo0cHR1VW3BGsjgxVlCnhbq+PdNdcGZExU6tS20Vaq1/4yv8qadXcukMcv0QGIzhV7BHVzHP+ibfvoqJroJ4vFypm7cx0VVoIzi6UDG/QO7WaZ/rNOOg3xzxvnXr1vLly8u8ydzc/HddlF69ek2YMEGVhZYyY8aMqKioMm+SyWRUatmv+9GjR3+3H/j5DV+pROZ20CkqA+zRVcrre/kivrxpZ8sybxUKhQUFBWXeJBaLSw6v/cLIyIjDUVcfIycnRyKRlHlTUVGRiYlJmTdZW1v/LmCHlyV1G+doag4fu2WAFFXWxd3f2g20pbMMcR/442t+fqakUftff50EMIb4nqiaoN7Wx9ekEF0FAbJSit88yIcIlQNSVFkmZtTAXtb/bEsnuhCNkkuVEVvT+kx1IroQrQZ7dH8m97vkQUR2jwkORBeiCTnfJBFb0kYucyfDzxXKBSn6Y6kfRTePZvSZ6mRips9d7cS3guc3YGDUSoEUVYWIL799MsvIhNKksyWTrW97xelfRE8u5di5s5p1KfuYJPgFpKjq3j3jPbmcU6cZ18aV6VKTTXQ5eIkFiq/v+FkpxbmZkqadLGxc9Hksf9WCFOH1/nnR55iitE9C32ZchVxpZEo1saCRkA48q2QKScSXC3hyIU8mFirSPwvdahvXqGvi5KnRAY/0AKRINRRyZfIHYVGeTMCTSSVKUZGKTwj9+PGjmZmZlZWVCtdJZ1JIZMQ2pRiZUs1tGXauhv5DwSrT5/6xJpEpJDdvNZ6+9nDelhq1W7Rt66O+TYAq07eeMQCaBykCAC9IEQB4QYoAwAtSBABekCIA8IIUAYAXpAgAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIgDwghQBgBekCAC8IEUA4AUpAgAvSBEAeEGKAMALUgQAXpAiAPCCFAGAF6RIN7DZbAoFrtygpSBFukEoFMrlcqKrAGWDFAGAF6QIALwgRQDgBSkCAC9IEQB4QYoAwAtSBABekCIA8IIUAYAXpAgAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF4kpVJJdA3gt0JCQoyMjBBCubm5TCaTxWKRyWQKhXLu3DmiSwM/UYkuAJTH3Nz88+fPZDIZISQWiwsKChQKxYABA4iuC/wL7NFptYEDBzKZzNJzHBwc+vXrR1xFoAyQIq3WuXNnJyen0nOCgoJsbW2JqwiUAVKk7fr168dgMLBpBwcH2J3TQpAibde1a1dnZ2dsOjAw0NramuiKwK8gRTogLCyMTqfb29uHhYURXQsog2EdoxMJFLnfi/n5UoVODUpV3SbIz/2du7t7frJRfjKP6HL+AJVBMrOmWzkwiC5EvQzo+6IXN/JSEkQIIXNbhrRYQXQ5BoFlTEn7JGSwyQ1bmzl5sokuR10MJUVPLuWKxcoGbSyJLsQQyWXK6wfSAntb27roZ6NkEP2iqNv5IiFEiDAUKqnjSKcbRzIKsqVE16IW+p8iuUz54WVRw3YQIYI1bGf16k4+0VWohf6nKD9LStL/R6kDOJa0tM9CoqtQC/1/fwkKZWY2+rk7rluMuTSFHCF97Ibrf4qUSiUckdMKSiTkyRCJ6DLUQP9TBIC6QYoAwAtSBABekCIA8IIUAYAXpAgAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIn326PG9kaP6BQX7v3v3FueqLl/5JyjYXyaTqag0vQIp0mfHjx9ACK1ft9PFxb2cxRITP4f166TBuvSNYY1eYmgEQkGDBo3r+vmXv1j8hzhNVaSfIEVlWLBwBo1G8/Gpu2PnBiqVWtPTe/asxZevnDt6bL+ZmXnbNp1GjZxIIpEQQrGxbw4d3p2Q8N7cwjKgUbNBA0dig9NHRJw4fvLg/HnLV65alJeX6+zsOn3a/NSUpK3b18rl8kYNm06ZPIfD4SKEvmd827VrU9y7mKIinquLe8uWIf36DkEInY04fvLU4SmT5yxaPKtbtz4JCe+NjU1WrthUusjcvJztWw+W+RCKi4vbdWiKEEpNTT537uTWzfu9vX2vXrtw6fK5pKQv7u7VgwJb9+zRl0Qi7d237djxAwihoGD/cWOn9u7V/+vXLxs2/R0b+8bezqF581bDh42j0WjYarNzssKX/RUfH+fk5BLaZ2DHDt009ZpoNdijKwOdTn8Z9TQp6cuZ09e3bTkYG/dm8tQRVCrt6uVHc+csPXnqcNSr5wihlJSkWXMmSGXSbVsPLlqw8tOnD9NnjFEoFAghGp1eVMQ7cmTvujU7LvxzVyqVLg2f8yjy3r49pw4fPBf9JurM2WMIIYVCMWPmuOycrOXLNpw+ebVZs6A9e7fef3AbIUSj0UUi4clTh+fOWdq9a58O7bu+fPm0kFeIVSgWi589f9ymdcffPQQGg3HvTpSTk0uPHmH37kR5e/veunV1zdrwmp5ex49eHDpkzJmzx7ZtX48QGjF8fFjoIBsb23t3onr36v/te/rkKSPq+NZbt3ZHaOig23eubdu+DlsnjUbbvGX14EGj1q/b6enptXHTyqysTE29JloNUlQGMplMpdImjJ/BMeW4uVVzd/MwNjYZPGgki8Vq4B9gbGT85ctHhNDtO9doVNrSxWucnV3d3T1mzlyY8DH+ydOH2BqkUum4sdMcHZ3ZbHajhk2zs7NmTJtvbW1jaWnl61P3S+InhNDz55HfvqXNnrnIs0YtDoc7cMBwHx+/a9cvIoQoFIpQKBw+bFxIcDtHR+eQ4PZ0Ov3OnetYhY8j7yOEWrVqW/kHdenKOV/fupMnzTYzM/ev32jYkLHnL5wuLCz4ZbGzZ48xmMwhg0fXq9ugS+eeQ4eMwa5YgRCSSqXduvZp1LBJXT//IYNHy2Sy9/GxqnvWdRikqGxOTi4luzEsNtvF2a3kJiNjYz6/CCEUFxdTs6Y3tmOGELKztbe3d4yJeV2yZLVq1bEJNpttZmbO5ZqVrBBbQ1JyIpvNdnZ2LblLjeq1sIhiPGt4YRN0Or1tm06371zD/n306G7TJi1NTUwr+XBkMtn797EN/BuXzKlbt4FcLo+NffPLkl8SP3l6elEoFOzfjh26TZo4q+TWOr71sAkTE1OEULFYXMkC9Bv0i8pW8gFc5r8YPr/o0+eEoOB/9d3z83NLprG+03+nS+Tm5rBY/xrrkM1mi0Q/h/ig0+kl05079Rwxqm9mZgaHw33+InLBvBWVfzhisVgul+/bv33f/u3/qrYg75clBQK+tZXN79ZDpcIbpgzwpFSduYWlD4s1dMiY0jM5ptzKr8HIyEgoFJSeIxAKLCysyly4WrXqNT29rl477+bmwWKxGzVqWvkNGRsbM5nMdm07t2gRXHq+g73TL0uy2UZ8Ab/yawaQIlyquVe/d++mX536Je1MUlKio6Nz5dfgWcNLJBIlJn52d/fA5sTHx7m5Vvvd8h06dDsbcTwx8XNIcPs/bRbc3auLxKKSo94SiSQz87u19a/NTk1P76vXzstkMmz9d+7euH794sq/N//RtgwN9Iuqrk+fgTK5bOv2dWKxOCUlaeeuTcNGhH5N+lL5NTRs2MTezmHt+mUfEt7n5eXu2789Pj6uT+/fXqEouFW7rKyMl1FPO7Tv+qfVjh456eHDO1evXVAoFG/fRi9dNnf6zLHFxcUIIUdH59zcnMjIB6mpyV0695RIJOs3rIh69fzR43t79m6xsrIp6SaBMkGKqo5jytm39xSTwRw9dsDgob1i3r6ePXNRdQ/Pyq+BSqUuC19vYmwybvzg/gO7vo5+uTx8vbe37++WZ7PZ9es3cnF2c3P7bXv1O76+dXftOPr2bXT3nq1nzh4vFAiWha/Hri8W0KiZT22/+Qun37l7w9HReeXfm9+8iZo5a/zyFfMDGjUbN3ban27L0Oj/aPdJ7wUxj3itwuyILkQFxGJxn9D2o0dP1sWvO5UKdGTZ5/HrPIguRPWgX6QbRCJRbm729p0bXN2qVWF3DqgVpEg3nDl77MDBnd7evosWrCw5mPHu3ds5cyf97i4njl82NjbWYI2GC1KkGwYNHDFo4IhfZnp7++7effx3d4EIaQykSLfZ2doTXQKAY3QA4AYpAgAvSBEAeEGKAMALUgQAXpAiAPCCFAGAF6QIALwgRQDgpf8pojEodKY+Xtha18hlSmtnJtFVqIX+p8jSnp6aIKzEgkC9ctLFFKp+fpzpf4oYLLKzp1FWCoxWQ7BvicKa9U2IrkIt9D9FCKHW/ayfXcniF8BI7YSJeZCHFAqvgMoO/aVb9P9cV0yxSHFybUqN+lyWMYVjSVPIiS7IMJDIKPdbsZAvE/OlbQfaEl2OuhhKijCxjwszksVSiVJUpGPtUl5+PpPJZLNYRBfyZziWNBqT7FCN7VHHiOha1MiwUqS75s2b16JFi7Zt/2BIYaAxBtEvAkCtIEUA4AUpAgAvSBEAeEGKAMALUgQAXpAiAPCCFAGAF6QIALwgRQDgBSkCAC9IEQB4QYoAwAtSBABekCIA8IIUAYAXpAgAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIgDwghTpBi6XS6VSia4ClA1SpBsKCgpkMh0bz9VwQIoAwAtSBABekCIA8IIUAYAXpAgAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIgDwghQBgBekCAC8IEUA4AUpAgAvklKpJLoG8FutW7em0WgkEqmgoIDJZDIYDBKJxGQyIyIiiC4N/ASnT2o1c3PzL1++YNPFxcXYRM+ePQktCvwK9ui0Ws+ePRkMRuk5jo6Offv2Ja4iUAZIkVbr0aOHs7Nz6TmNGjVydXUlriJQBkiRVqNSqd26dStpjpycnKAh0kKQIm3XvXt3FxcXbLphw4bQEGkhSJG2o9PpWHPk6OgYGhpKdDmgDHCMrmxKJcrLkAiLtGLwqoY+7T0cnnl5edFktqkfhUSXg0hkEteSZsyFN88P8H1RGSIv5cY9KTC1oDOY0FaXwciM9u2zkGtJq9OC6+5jRHQ5xIMU/erm0UwjLt23mRkiEV2KdpNJlPfOfPdtYurhZ0x0LQSDFP3L7RNZJhYMr0YcogvRGbeOptcNNHPzZhNdCJFgj+WnzGSxVKKECP2R5t1tYx4WEF0FwSBFP+V8l1AosBv3Z5hGlKxUcbFQQXQhRIIU/STgyc1sGJVYEPyLnRu7MEdCdBVEgoOVP8mlCugkVoGAJ0Ukg27DoS0CAC9IEQB4QYoAwAtSBABekCIA8IIUAYAXpAgAvCBFAOAFKQIAL0gRAHhBigDAC1KkVzp3DTx2/ADRVRgcSJFeCQsd7FPbj+gqDA78pluv9O83lOgSDBG0RbgkJSUuXjK7a/fgHr3aLFg4Iy4uBpvfpl3jk6cOlyz296pF4yYMQQi9j48LCvZ/+OjusBGhQcH+vfq027FzY8liOTnZS8Pnhvbt2KVbq+V/L0hNTcbmf/qcEBTs/+zZ41592o0Y1XfchCFz/ppcuoy586ZMmjKi9B6dUqk8c/bYyFH92ndsNmbswD17t8rlcmzh6DdRk6eO7Ni5RdfuwZOnjnzy5CE2/2zE8V592j2OvB/cuuG+/dvV/+TpD0hR1Ukkkmkzxsjl8g3rdq1auYVMJs9bMK1kTPoyMegMhNCxY/tXLNt4/WrkuLHT/jl/6uq1CwghmUw2bcaY2Lg3M6YvOLj/jKkpZ/yEId++pyOE6DQ6Qmjv/m2hfQZOnzY/KLD1q1fPBQIBtk6xWBwV9axVUNvSGzp37uT+Azt69ex37MiFTp16XLl6/szZYwih9G9p06aPcXJ02bvn5LYtB7gcs0VLZuXkZCOEaDS6SCQ8eerw3DlL27XrouYnT69AiqouNTU5Pz+vb98h7u4e1T08Fy74e/GiVTJZeUPYkUgkhFCLFsG2tnYMBqNVUJsGDRrfvXsDIRTz9nVqavLcOUsb+AeYm1tMGDfdxJRz7txJhBCFQkEINW3Ssnev/rVqercKaiuTyZ48eYCt83HkfYVCERTUpvSGYt6+rlOnftu2nczNLTp17L51y4EG/o0RQhcvnrWysp4yeY6drb2jo/PMGQspFMrNW1ewrQiFwuHDxoUEt3Owd1Tzk6dXIEVV5+jozOWarVq9OCLixIeE9xQKpa6fv5FRxeOzVXOvXjLtYO+U+PUzQig29g2NRqtXtwE2n0Qi+dWpHxsbXbJkjeq1sAkLC0tf37qPHt/D/o2MvN+gQWOO6b8GXaldu05U1LPVa5Y+jrxfxC9ydHCqVq06Qig55atnDS8q9Ud/2NjY2NnJNTHxU8kdPWt44XtWDBEcXag6BoOxacOeK1fPHzm2r7CwwMHBacjg0SHB7Sq8I5PJKjXNFImECCE+v0gqlQYF+5de0sLCsmSaXuoSLIEtW+/avUksFlMolKfPHk2dPPeXTfTs0ZfFYj95+nDBwhlUKrVVq7ajRky0sLDMy81xdv7XSN9MFkso+jneKp1O/8OnAUCK8HF2dh07ZsrQIWOiop5dv3lp+Yr5ri7uHh41fllM8f+ePYbPLyqZFovFLBYbCwyLxVq+bEPpJamUsl+gwJYhW7etffb8MZVKVSqVLVoE/7IAhULp3KlH5049kpISX716fvDQLqFAEL50LdvISFwsLr2kSCh0cXar6hMAEKQIl+Tkr/Ef4tq17cxkMps1CwwIaNa2fZOEj+89PGowGAxRqQ/4lJQkCvXnU/0m5lWzZoHY9OfPCe5uHgghd/fqIpHI1tbeztYeuyn9W5q5mUWZmzYzM69fr+HLl0+LinjNmgayWKzStyqVyps3r3h6erm6umN/vKLCGzcvYztst25flclk2E4dr4iXnPIVjiXgBP2iqisoyF+1esmOnRvTv6UlJSUeO35AoVB4e/kihLy96zx6fA87jHbk6L7cvJzSd3wZ9fRl1DOE0IOHd6LfRLVq1RYh1Khhk4YNm6xZszQzM6OwsODcP6fGjht07frF3229ZcuQmJhXr6NfBAW2+eUmEol04+blRUtmPX36iFfEe/bs8ePI+1hhnTp2Lyrird+wIjMzIykp8e+VC1ksdntIET7QFlVdnTr1pk396+ChXafPHEUINfAP2LBul6urO0Jo4oSZ69Yt69SlJZVKDe0zMCS4fXT0y5I79gsbsnPXxlmzP1MolJ49+nZo3xWb//fyjRcvRSxdNvf9+1gnJ5d2bTv36P7bS60Etmy9fsMKBoMRENDsv7fOnrV467a1f82fiu0rdurYvXevAQghJyeXRQtXHjmyN6xfJy7XrFat2ls27WOzDXp8YPxgnO6fnl7JVSrJPs3N1LeJxMTPw0eGbdqwx9e3rvq2omFX9qa26mNt7WS4A2LCHh0AeEGKAMAL+kUa5e7uce9OFNFVABWDtggAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIgDwghQBgBekCAC8IEUA4AUp+olpRKHS4Qn5Y6bmNDIVrjEOEMLeDZnJwkosCEpRosRYvqWdQY/WACn6yak6u1gor8SC4KfMZFFNf1OiqyAYpOgnOovkF2h26+g3ogvRGcUixYOzGUF9rIguhGBwruuvUj+K7p3O8mlqZmbLYLApRJejjchkVJAtERTKXt3OGTTflcEy9M9iSFEZCnOk0Q8KctKK+YXlDXQqk8nkcjmDobdnSouEQjqDgY3MWpqZNV2pRI4eLP/Wajy7XodAiqqouLh4xYoVS5YsIboQNeLxeBs3bly4cCHRhWg7SNEfe/HiRXFxcZMmTf77Ia2vDh8+bGNj07Zt20osa4gMfY/2T338+PHgwYMGFSGE0KBBgx4+fJicnAyfuWWCtqiyPn/+7OLikpGR4eTkRHQtxCgqKpJKpbdu3QoN/e0oeYYJ2qJKiYyMnD9/PpVKNdgIIYRMTEzMzc1TUlKOHj1KdC3aBdqiCvB4PFNT0/v37wcGBhJdi7b4/v27nZ3dtWvX2rdvT3QtWgHaovLcuHEjPDwcIQQRKs3Ozg4hJJfL+/fvT3QtWgHaovJs2bJl4sSJRFehvdLS0hwdHd+9e+ft7U10LUSCtqgMjx8/Pnz4MEIIIlQ+R0dHhBCbzQ4JCcnLyyO6HMJAin6VnZ199uzZQYMGEV2IznBzc4uIiEhPT8cunUR0OQSAPbqf3r17x2QyraysTE0N/UfKVdagQYPdu3fXras/V8SoDGiLfoiJiVm9erWrqytECI+XL19+/PgRISQUGtCZWtAWoaysLGtr69jYWB8fH6Jr0R8rV650dnbu168f0YVogqG3RY8ePZoxYwZCCCKkWnPmzMnMzCwuLhaLxZVYXLcZborkcjlCKCMjAzscB1Ru6tSpNBrtw4cPO3bsILoW9TLQFN29e3fZsmUIod69exNdiz4jk8l+fn4MBuPatWtE16JGBpqi69evL1q0iOgqDMWwYcNatmyJfYtNdC1qYVgpiomJuX37NkJo9erVRNdiWLDLmFerVm38+PFE16J6BnSMLjk5OTw8fMeOHTQajehaDFdxcTGDwbhy5UpISIjenGxvEG1RSkpKUVERlUrdu3cvRIhYWHI8PT1btWolEAiILkc19L8tevXq1fLly8+cOWNQZ6fqhPz8fKFQSKVSbWxsiK4FF31ui0QiEUJIIBCcO3cOIqSFzMzMLCwshg8f/ubNG6JrwUVvU/Tw4cMpU6YghFq0aEF0LeC3mEzm5cuXJRIJ1nElupwq0tsUxcTE7Nq1i+gqQKU0bNgQIbRr1679+/cTXUtV6GG/6Pnz5x4eHhYWFkQXAv7YhQsXunbtSnQVf0wP26IDBw58/fqV6CpAVehihPQzRQ0bNoSGSEfdunUL+2WWbqESXYDqDRs2jOgSQBXJZLLi4mKiq/hj0C8CWkShUCgUCipVxz7c9XCPDvpFuotMJutchPQzRdAv0l03btxYunQp0VX8Md3LfYWgX6S7FAqFVColuoo/Bv0ioEWgX6QtoF+ku6BfpC2gX6S7oF+kLaBfpLugX6QtoF+ku6BfpC2gX6S7oF+kLaBfpLugX6QtoF+ku6BfpC2gX6S7dLRfpGPlliMkJIRCoZDJ5IKCAjabTaVSyWQyl8s9ceIE0aVxAunOAAAgAElEQVSBCvTs2VMkEikUCqVSSSaTSSSSQqGQSCR3794lurRK0Z8UcbncpKQkbLqwsBCbaN26NaFFgUqpUaPGjRs3yOR/9dLt7e2Jq+jP6M/RhcaNG/8yx83NDYbh1gn9+vWztbUtPUepVOrQea/6k6KwsDB3d/eSf0kkUuPGjZ2cnAgtClSKj49PvXr1Ss9xdHTs27cvcRX9Gf1JkYODQ+PGjUv2CpycnKAh0iFhYWF2dnbYNIVC6dKlCza0t07QnxQhhEJDQ7GrXiOEAgICoCHSIbVr1/b19cWmnZ2ddagh0rcU2dvbY70je3t7A7kWoj7p27evtbU1hULp1KmTDjVEqjxGxy+QSyUKVa2tyjq1DXv2KC4gIMCIbpOfRfD3dySETC1pZB3/pBILFCKBXAMbcrD29KnZOCUlJbhFV828dhQKMrVQwdUPVPCta+Sl3PfPC81tGEKeDH9B+sTEgp7+WeBc06hBiJmtK5Pocv7Y63sFMQ8KyFQSmUR0KerBsaJ//yryrG8S2MsKz3pwpUipQP/sSHf1MnGuacRgw3DyZePny+6fzWje1dKxui4F6dE/OVIp8m7MZZvqz5eK/yURKzKTRS9vZA+Y40KhVfHTAleKIram1/TnOtcyqvIaDMeVvWnNulo4erCILqRSHkRkk6kUv0BzogvRkIIsyb3T3wfNc6na3au+z54QVWTtxIIIVVKrMLvXdwuIrqJSMlOKxUKl4UQIIcS1ptdqwH1zv4ovUNVTlJEsZsJeXKWxjClZKWIRXxPddJyyUsVkip72hH6PzaGmfxFV7b5VT5G0WGFmoyfX5dQMJ092XqaE6CoqJuDJLR11qQunElxrRpX7NlXvOPIL5XI58Ye2dQi/QIZ04TQUiUhBpuhAm6laSoWyIKuKn3E6/l0GAFoAUgQAXpAiAPCCFAGAF6QIALwgRQDgBSkCAC9IEQB4QYoAwAtSBABekCIA8IIUATXqHdp+775teNawaPGs6TPGqq4itYAUVUVi4uewfp2IrkJvLV4y++q1C3jWcO6fU3+vWqSygioCKaqK+A9xRJegzz4kvCN8DX9Ec6fUf/qcMGp0/7+Xb1y7fhmXa7Z394mvX79cvHT21esXWVkZLs5unTv37NSxO7Zwbm7OqtWL371/6+zs1q1L79S05MgnDw7sO13+Jp4+fXT33o2Yt6/5/KJaNWsPHDDCz68+dtO7d283bV6Vlp7i61tv0IARO3ZtrOZefcrkOQih2Ng3hw7vTkh4b25hGdCo2aCBI42MjBBCEREnjp88uHTxmtVrl6akJLm7e/TpNaBt20579207dvwAQigo2D98ydpmzQLV/+RpO7lcfur0kcNH9pBIJK9aPkOHjKlduw52E5VKO3fu5I5dGxkMRu3afnPnLOWYcn73YslkstZtAxBCa9aG79i54dKF+9ggj1Gvnp88eejd+7fVqtWYNHFWjeo1EUIikWjf/u3Pnj3Kys60sbGr41tv/LjpLBZr4uThcXExCKGYmFcnj1/WwMPXXFtEp9ERQnv3bwvtM3D6tPkIoS1b10S9ej5tyl8nj1/u0KHbuvXLX0Y9wxZevWZJamryurU7lyxaHfnkwbPnjymUCs6rFQqFy1bMk8lkSxavObDvjIOD07wFUwsK8rGn+6/5Uy0srfbvPT1s6NgtW9dkZ2dSqFSEUEpK0qw5E6Qy6batBxctWPnp04fpM8YoFAqEEI1OLyribdm6ZvbMRXdvv2zerNWadeHZ2Vkjho8PCx1kY2N7704URAiza/fmS5ciwpeum//Xcksr6zl/TUpLS8Fuunf/pkAoWL1q68wZC+Pi3hw4sKOcF4tKpV6/GokQmjljARYhhNDXpC8XL57t33/YiuUbFQrF/AXTsMFCNm1edffejXFjp0WcvTl0yJh792/u3rMZIbRl075atWq3adNRMxHSaIqwGDRt0rJ3r/61anojhBYtWrVm1TY/v/pcrlnXLr2qe3i+ePEEa4hevHwaFja4pqeXtbXN9GnzMjK+Vbh+Npu9d8/JKZPn1KrpbWNjO2rkJKFQiH0mRT55wOMVjh09xdbWrkb1msOHj8/MzMDudfvONRqVtnTxGmdnV3d3j5kzFyZ8jH/y9CF2dUSpVDp+3HQvLx8SidSmTUe5XP7xY7z6nyodU1CQf+bssbCwwQ38A5o2bTlz+oK6fg1ycrKxW42NTQYOGF7Xz79li+AmTVq+jY0u/8X6r/z8vEkTZ9X186/r5z9o4Mjs7Ky3b6N5Rbw7d68PHjSqSZMWJsYmrYLa9OgedvPWFZmMgOHcND1IUo3qtUqmlQrFmYhjL148KfnccnFxwz57EEI+tf2wmRwO18/PvzJBEgoEe/dujXn7Ojc3B5tTUJiPEEpOTjQ15Tg7u2Iz/es3MjY2xqbj4mJq1vTmcLjYv3a29vb2jjExr5s1/dHI1KzpjU0YG5sghPj8IhU9E/oj8etnhFCtWrWxf6lUavjStSW3lryOCCETE1NJcTE2/bsX67+quVe3tPwxXlxt7zoIoe8Z6TQ6XSaTeXn5lCzm6eklFAq/f093cqriUD5VpukU0Rk/hmqQy+Wz50xUKpWjRk708/M3MTYZN2EIdpNAwEcIMVk/B50y45pXmKKMjO+Tp45o4N94wbwVXl4+CoWiXYemP1YoFLBY/xrCyszsx5X2+PyiT58TgoL9S9+an59bMk0iGdw4Hn8K+2Rhs8oeE7jMC+OV82L9l5GRcck0NvJwUREvLy8HIcRk/BwfgsViI4SEIiHuB/THCBuwLyHh/cdPH9at3VGvbgNsTsnHPIPOQAjJSzXN+QV5Fa7w7r0bUql09qzFTCYT2y0suYlBZ/zS0Ofm/tjfMLew9GGxhg4ZU/pWjikX34MzLNi7vOhPWulyXqz/Eol/Ds3DF/ARQqYmHGyjpW8SCgUIIUsLXKOcVg1hR7oLCwtKP+bExM+pqcnYtL29Y8l+HUKIz+e/fv2iMis0MTHFXhWE0IOHd0pusrNzyMvLxbaIEIp+EyUU/vjEquZePSc7y69OfWy3u66fvxnXvGTfD1RG9eo1KRRKTMwr7F+lUjnnr8k3bpTXsy/nxfqvlJSvYrEYm46Pj0MIOTo6V6tWg0KhlO5KxcfHcThcc3MCrudLWIpc3aqRSKQzZ4/x+fzk5K/bd6xv4B+QkfkdIeTs7Ork5HLw0K5v39P5fP7GTX/b2TlUuEKPajVyc3OuXD0vk8mePY+MjY02NeVkZWUghBoHNCeRSJs2rxKJRGnpqUeO7LWyssbu1afPQJlctnX7OrFYnJKStHPXpmEjQksC/DuOjs65uTmRkQ+ys7NU9HzoMFMT0zatO164cOba9YvRb6K2bF3z6tVz7/8f6S5TOS8Wg8GwsrJ+/fpF9JsomUymUCiYTNba9cuK+EV5ebnHju+3tbHz8vIxNTENDm535OjeJ08eFvGLbt688s/5U7179cf2wB0cnBIS3r9791YzzwBhKbKztZ/317LYuDeduwbOXzh9+PDxXbr0iouLGTYiFCE0e+YihUIxYGC3qdNGeXp61fauQ6NWMLZ/SEj7/v2GHji4s3XbgH/On5o4YWab1h2PHN23afMqKyvrqVPmRr+J6t4zZNXqxQMGDGex2FQKFSHEMeXs23uKyWCOHjtg8NBeMW9fz565qLqHZ/nbCmjUzKe23/yF02Pevlbps6KrJk+a7efnv2798mnTx8TGvglfstbRobyLR5XzYiGE+vcbFvXq+YKF00VikUQq8fWp6+zk2qt329C+HRFCy8LXY1GZOH5mk8Ytwpf/1aNn6+MnDw4cMCIsdBC2/s4deyiVyuUr5mvm4Vd9nO7zO77VCuDau6vlOjOFhQVisdjG5se1PufOm8JkMBctXFnlFaZ/SzMxMTU1McV2OTp1aTli+ITu3fqoruSK3TycHtDe3EHrh+p+eC6HaUyt1ciwOoeFOdL7p78NmFuV43taejmABYtm5OZkjx0z1dvb9/KVf169ev73ik1VXlt+ft7YcYOwb4o4HO7+/dspZErLFsEqLRkYLi1N0dLFa9asC9+5e1NubraLs9vihavq12t46vSRo0f3lbm8m7vH5o17f7c2MzPzv5dv3Ltv24KF0yXFxbVq1d665QAh3VCgl7Q0RVyu2fLw9b/M7NChW4vfNCAV9pq8vX03rN+lugIB+ElLU1QmE2MTE2MToqsA4FdwZgQAeEGKAMALUgQAXpAiAPCCFAGAF6QIALwgRQDgBSkCAC9IEQB4VT1FpuY0EmTwT5iY00hkHTj/nGlEoTEM7qUlkUjmtvSq3bfqTxadScr7VsUrmxumr3F8S/sqvk6aZMylZKWIia5C03K/i8lV/YyreoocPNgiAQGjFukoXq7UqQabztSBz3g7N5ZMqiC6Ck3jF0idPKt4slzVX1Q3b7ZEJH9zv+JxRQBC6OaR9KaddeNcDDNrmq0z49E/mUQXojmfonkZX4XeAaZVu3vVz3XFPIjIUSpJjjXYlvZMCk0Hdvo1jJcr5eVKH57L6D/L2dhMl35B/+550afXRTUbci3tmQy2DjShVaBUoJx0cXaaODNZ2GW0fZXXgzdFCKH3z3nxL3kyqTI7tRjnqvSMpT1DKlG41GQHdLDQiX25XyTHC988LCjMlvDy9HPX3daVpVQqq/uZ+LXk4FqRUu+MHj365cuXRFehVCqVCjnRFeB269atxo0bv379WjObGzNmTOfOnTMyMipcsmfPnklJSRopqmK6tI+hc3T9m4BFixYVFxc/efJEM5uLjIxMSEgoKiqKiIgYN25c+Qvv2bMnJ6e8sSA1ScdfZ6Ae0dHRgYGBjRo1Wrmy6uMu/anjx4/zeDylUnnnzp3MzAqObZiZmVWvXl1TpVUAUgR+tWnTpu3bt1++fLlDhw4a22hkZGR8/I/rcaSkpJw5c6bCu7x+/XrChAnqL61ikCLwU3Jycs+ePc3Nzffs2VNyWQ3NOHbsGI/Hw6aVSuX9+/crbI7q1avn4uISGxurkQLLA/0i8MORI0fOnz+/fv16FxdNX7nk6dOnCQkJped8/fr19OnTEydOLP+OM2fOVHNplQJtEUB8Pn/UqFF5eXkRERGajxBC6ODBg3l5eUqlUqFQKBQK7NuXe/fuVea+jx8/Tk1NVX+N5SL6IKHqac+Rbp1w5cqVli1bvnr1iuhClEql8urVq/Pnz/+ju6SkpHTr1k1tFVUK7NEZtDlz5tDp9Pv37xNdSNU5OTmtWLHi27dv9vZV//EBTrBHZ6CeP3/epEmTkJCQpUuXEl0LXrVq1SIwQnB0wUCtWbMmKSnp/v37dLoOnKlRGXv27DE3N+/ZsychW4e2yLB8+vSpc+fOLi4u27Zt05sIIYSGDRt24sQJorYObZEB2b9//61bt3bv3m1nZ0d0LSpGoVDOnj1L1NahLTIIeXl5Q4YMKS4uPnHihP5FqMS1a9fkcrnmtwsp0n/nz58PCwubOXPm2LFjia5FvQoKCjZu3Kj57cIenZ6bNm2aubn5zZs3iS5EE/r27Xvt2rXi4mIGg6HJ7UJbpLcePnzYoEGDbt26zZ+voYsEa4P27dtrOELQFumt5cuX5+bmvnz5kuhCCDBp0qQ5c+Zo8hskaIv0zbt379q2bevl5bV+/a+X9DQQvXv33rVLo1cfhbZIr+zYsePZs2fHjx+3sNCN8YbUoXnz5s2bN9fkFqEt0hMZGRl9+/al0+mHDh0y5AhhCgsL4+LiNLY5SJE+OH369IgRI5YuXTp8+HCia9EKHA5n27ZtGusWQop0m0QimTBhQnJy8uXLl7VnHAJtEB4enp2drZltQYp02N27dwMDAwcMGKAlp3xqFUtLS42NG6GHRxccHR2pVD18XL8IDw+XSCQaG+ZKM+h0uqWlparWlpmZeeLEiSlTpqhqhb+jh22RiYmJNoxooT5paWmdO3f29fUNDw8nuhYVCw4OjoiIEAqFKlnbly9fvn79qpJVlU8PU1SrVq2SMZn0z7lz5yZMmLB79+6uXbsSXYta9OzZMyIiQiWr8vb2njdvnkpWVT5IkS6ZM2dOQkLC+fPn9fh32T169Dh37pxKVsXhcKytrVWyqvLpYYqcnJzy8/P5fD7RhahSQkJCq1atQkJC5s6dS3Qt6uXk5GRra6uSg9QbN2589uyZKoqqgB6mCCHk5eX1/v17oqtQmcOHD4eHh58/fz4kJIToWjRBVTt10dHRJiYmqqioAvqZolq1an348IHoKlRj4sSJBQUFR48eNTWt4jWqdE5ISMiLFy9KhkqtsmXLltWsWVNFRZVHb1OkB23Rq1evGjVq1K9fv0mTJhFdi6appHfk5OREoVBUVFF59DZFun6AYceOHbt3737y5Enjxo2JroUA+HfqUlNTJ0+erLqKyqOfKXJwcCgqKsK/S0AIsVg8bNgwOp2+a9cuzXyUaiE7OztXV9enT59WeQ1JSUlksobe3vqZIt1tjh4+fBgSEjJlyhT4XSnOnTp/f3+NDVgJKdIia9euPX/+/OPHj319fYmuhXhBQUExMTF5eVW8iD2LxdLMATp9TpGXl5cOpSg3Nzc0NNTR0dFgT1AtE57mKDw8PDIyUtUVlU1vU6RDh+muXbvWv3//FStWhIWFEV2LdsGTooSEBI2drai3v322s7MTiUSFhYUcDr6LsKvZkiVLZDLZ9evXiS5EG1lbW3t6ej569KgKZ4Bv27ZNY9+w6W1bpP3NUXJycqdOnerVq6d/P81WoSo3RxwOh0QiqaGiMuhzirS5a3T27Nlp06bt27evc+fORNei1Zo3b/7hw4c/PWs1MTFxxIgRaivqV3q7R4cQqlmz5tWrV3v27FlYWFhUVPT8+XOiK/ph1qxZ5ubmqvr9v97DvoEdM2ZMhUu2a9dOKpWyWCyJROLl5aWR6hBCiIRdQ1OfDB06NCsrKycnRyaTKZVK7Ks3W1vby5cva76YiRMnxsTEPHz4EPv3/fv348aNW7hwYatWrTRfjI7Ky8sLCwurzCDJs2fPvn37dukdOexasdHR0WqtUA/36A4cOCASieRyOYlEwiKkUCgI+Snn06dPP3z4IBQKsd22Q4cOrVy58vLlyxChP2Jubu7r61uZy2a2b9/+l4NJZDK5V69e6qwO6WeKEELdu3cvPfQCmUxu1KiR5ss4cuRIbm4uQig9PX38+PE8Hu/w4cPGxsaar0TXVfJndQEBAWZmZqXnODs7z5kzR52lIb1N0cSJE+vXr69QKLB/jY2N/f39NVzD/fv3P336hDWGZDL55cuXEydO1HANeqNx48ZJSUnfv38vfzEmk+nn51fSSbGwsJgyZYoGfouonylCCG3evNnFxQWb5nA4muxrYg4dOoQ1RBiFQmEg59ipSSUPebdt25bL5WLTgYGBmhlqWG9TRKFQli5damlpqVQq7ezsfmno1e3+/fu//KZYoVDk5+e3a9dOk2Xok0ru1DVs2JDL5SqVShcXF42dXV/ZI91Sie4dyqvpWXvokJFbtmxp0riFhuvft/dQEU9EItGYTKaRkRGVSrW2tnZwcFi4cKEKKyEhElWXL3AsFSsr/zHOYpo0bNDkxvU7FR6badK4RU52waSJ0/A/1TR6pb63reBId3K8MPpBQVaKWKHQvRRh5HIFhaLpJlcmk5EQiUQmkRAJkdT1HbqNM4ufL3X3NW7aWZeGtxcUyp5dy0uOFxhzaXmZxZW/o1KJlEolmayhXyRg7NxYdVtynWuyy1mmvBTFvyj68KrIt7m5uQ2DWrlQAg3j5UrzM4sjL2SOCK9GoRFdTSUUZEvPbU1r3sOOY0FjmWj7OYgyiTI/szjmQZ5XgKln/d8eXP1tit48KEj/Utyip406iwSqIeTJzm9PGf23O9GFVCDnm+Tage/dJrgQXcgfe3A2w9mT5dus7F82l72rwy+QpX4SQYR0BduU2qSz9dMruZVYlkjPr+W2HuhAdBVV0bKXbXK8UMCTlXlr2SnKSBaTEOzC6RKOJf3rOwHRVZRHLFR8SxQZcXT1p5tKJcpMLrsXV3aKivJk1i4sNVcFVMnMhs5ga/UbNC9T4lJLh3+3YePC4uVLy7yp7OddIlZIy14eaK/viaq51IKaKBXKojwdfldJxIrf7Z7p7beuAGgMpAgAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIgDwghQBgBekCAC8IEUA4AUpUr3c3JygYP+Hj+4SXQhAEedOhrRR+yBqkCLCJCZ+DuvXiegqtJquPEWQIsLEf4gjugRtpytPkcrOSOnSNSgsbHBObvY//5zics2aNmk5aODITVtWPXny0NnZdUD/4a1D2mNLXr124dLlc0lJX9zdqwcFtu7Zoy82useChTNoNJqPT90dOzdQqdSant6zZy2+fOXc0WP7zczM27bpNGrkRGzJ6DdRBw/t+vw5gUqlubq6h/Ye2KRJC4TQ2YjjJ08dnjJ5zqLFszp06HbjxqWhQ8b0DRuMbVcul3fv2bpjh26jR/32wvfHjh84emzftSuPsX+/fU/vP6Dr38s3BgQ0O3Hy0KnTR6ZPm7d+w4rCwgJ7e8fBA0e2bt0BW/LO3RsHDuzgC/iNA5r36tmvZIV8Pv/M2aMvXjxJSk40N7ds1jRw6JAxTCZz775tx44fQAgFBfuPGzu1d6/+sbFvDh3enZDw3tzCMqBRs0EDRxoZGanq1dFFl6/8s2798tJP0feMb7t2bYp7F1NUxHN1cW/ZMqRf3yHYwr97S5SWlJR48NCu6DdRFArF28s3tM/A2rXrqKRUlbVFdAbjxImD7m4eN68/HT5s3JWr52fOHt+mdcfbN583bxa0dl24QCBACN26dXXN2vCanl7Hj14cOmTMmbPHtm3/cQ1GOp3+MuppUtKXM6evb9tyMDbuzeSpI6hU2tXLj+bOWXry1OGoV88RQunf0qZNH+Pk6LJ3z8ltWw5wOWaLlszKyclGCNFodJFIePLU4blzlob2HhAU1ObO3Z9X14p+E1VUxGvXtopXOmHQGQIB//79WyeOXfon4lZQYOu/Vy1KS0vBdjyWr5jfpk2nw4fOhYS037JtTcm9zkYcP37iYFjY4ONHL04cP+PO3etHj+1DCI0YPj4sdJCNje29O1G9e/VPSUmaNWeCVCbdtvXgogUrP336MH3GmJKxXQ1Tp47dSz9FCoVixsxx2TlZy5dtOH3yarNmQXv2br3/4Hb5b4kSEolk2owxcrl8w7pdq1ZuIZPJ8xZMKy7+gxGIyqGyFJFIJD8//04du9NotKDANgghf/+Ali2CKRRKUGAbiUSSkpqEELp05Zyvb93Jk2abmZn71280bMjY8xdOFxYWYMPwUqm0CeNncEw5bm7V3N08jI1NBg8ayWKxGvgHGBsZf/nyESF08eJZKyvrKZPn2NnaOzo6z5yxkEKh3Lx1BRvJUSgUDh82LiS4naOjc6cO3b98+fT16xeswgcPbtf09HJxcavaA1QiJJPJenQPYzKZHA532NCxRmyju/duIoQuXDxjY207aOAIUxPT+vUadmzfreReYaGD9u4+0bJFsJmZeUBAs8CWrV++LOPq87fvXKNRaUsXr3F2dnV395g5c2HCx/gnTx9W9dXQQ8+fR377ljZ75iLPGrU4HO7AAcN9fPyuXb9Y/luiRGpqcn5+Xt++Q9zdPap7eC5c8PfiRatksrLHUfhTquwXublVwyawXREX5x/vVxabjRDi84tkMtn797EN/BuX3KVu3QZyuTw29g32r5OTC41GK7lXyRoQQkbGxnx+EUIoOeWrZw2vksHsjY2NnZ1cExM/lSzpWePHYMI+Pn4ODk63bl/FrsDx4OGd1q074nyMHh6e2ASJRLK3d0xK+oIQSk9Pdf3/Y0cI1azpXTJNo9FevHwydvzg1m0DgoL9I86dyMsvY4yRuLiYmjW9OZwfQ+Pa2drb2zvGxLzGWa0+SUpOZLPZzs6uJXNqVK+FfbBW+JZACDk6OnO5ZqtWL46IOPEh4T2FQqnr56+qfWZVnqn/y+CFpcfXxYjFYrlcvm//9n37t5een1+QV+Zd/rsGhFBebk7ppxIhxGSxhKKfJ0vT6T/HC+3apdeZs8dGjZwY/SZKJBKG/L9vVmUMBuPnNJMpEosQQjxeYemSmMyfQ1Zs37nh1q2ro0ZObODf2MbGdtfuzbfvXPvvavn8ok+fE4KC/zUkf35ZeTNYubk5LNa/hlZks9kikbAybwnshdu0Yc+Vq+ePHNtXWFjg4OA0ZPDokGDVDPis0fEujI2NmUxmu7adW7QILj3fwd6p8ithGxmJi8Wl54iEwtKtVmltWnfcvWfL6+iXjx/fa9K4hanJn13FSCGX/zJHIBCUfIAVi8WWFlYIIVNTTuk9bKHwx1g8CoXi6tXzfXoP6NSxOzYHa07/y9zC0ofFGjrkX5eL45hy/6ha/WZkZFTyxGIEQoGFhVXl3xLOzq5jx0wZOmRMVNSz6zcvLV8x39XF3cOjBv7aNH2k2929ukgsquvnj/15e/laWlhZW//BwHeeNbzev48t2aPlFfGSU766ulYrc2EOh9uyRfC9ezdv37neOqRDhSun0+kSiaRk5cnJX39ZIPrNS2yiuLg4JTUJ266Njd37+NiSgwHPnv84xCeRSMRiMfZKY/8+ffaozO1Wc6+ek53lV6d+yTNjxjX/5fPVwHnW8BKJRImJn0vmxMfHublWq+RbIjn56/Ubl7CrszRrFrh44SoymZzwUTUXz9Z0ikaPnPTw4Z2r1y4oFIq3b6OXLps7febYPzpU0qlj96Ii3voNKzIzM5KSEv9euZDFYrdv1+V3y3fs2P3W7atkMjkgoFmFK/f2rqNQKLCuVGZmxsnTh0vfSqVSz507mZaWIpfL9+7bVlxc3CqoDUIoMLB1Xl7u9h0blEpl9JuoixfPYsszmUwHB6frNy6lf0srLCxYvXZpXT9/Hq9QLBZje+q5uVPY4lkAAAwaSURBVDmRkQ9SU5P79Bkok8u2bl8nFotTUpJ27to0bETo16QvlX9a9FLpp6hhwyb2dg5r1y/7kPA+Ly933/7t8fFxfXoPqORboqAgf9XqJTt2bkz/lpaUlHjs+AGFQuHt5auSOjWdIl/furt2HH37Nrp7z9YzZ48XCgTLwteX7mxUyMnJZdHClV++fAzr12nq9NEkEmnLpn1s9m8HI6/r50+lUluHdCh9db3f8apVe+yYKTt2bAgK9l+6bO7woeOwL5pKFujZo+/kqSND2jS6dv3C3NlLHB2dEUIN/ANGj5r09OnDViENVq1ePHvWYmx3DiG0cMHfNBptyNBeAwZ2a1A/YNiwcXQavUu3oKyszIBGzXxq+81fOP3O3RscU86+vaeYDObosQMGD+0V8/b17JmLqv//SIbBKv0UUanUZeHrTYxNxo0f3H9g19fRL5eHr/f29q3kW6JOnXrTpv51+861AQO7DR3e5927mA3rdrm6qmZM5rLH6X5+LU8qRXVamqtkG8R69+7txMnDDx+MwN7xVRZx7uT2Hevv3HqhutJU7NCSzxPWexBdxW+lfxE9u5LXZrBOjjCMEHpzP4/BRA3blhEKrR5NEyeRSPQh4d3GTSsH9B+GM0IAlEOfUzR/wbTX0S/btuk0eNCokpmnTh85enRfmcu7uXts3rhXgwUCPaHPKVq3dsd/Z3bo0O2X4+wlaNTyLgDUs0dYzx5hqqsO6A99TlGZTIxNTIxNiK4C6BU4MwIAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIgDwghQBgBekCAC8yv7tAp1JJlN/d0FloKVsXVlIiZC2vm4kEsnYvLzfWGk5BotCp5dxAsRv2yJjLjUrVaTmqoAqFWRLioVyrY0QQsjMmpb6QVCJBbVUZorQxLzsVqfsFFk7MtVcElAxXq7MxUurR4FkGVNsXJgiga4OskciISuHsnNRdoo4VlRrR8bTS1lqLgyohlKB7p/51qyLBdGFVKBBa7Pbx9KJrqIqnlzIsnNlmlqU3RaVfa4r5vXdwu9J4jotzTmWOrw7q9+KhYq8jOKbR9NHLatGZ2nx/tz/ZaQU3zqWGdjL1sScRtGFvndhjvTN/VxHD5ZfS87vlikvRQihhFdFMQ8KczOKWWyKeorUNJlcTiaTySQdeP0qZOHAyEgWefiZBPawIunO0dbc75KXN/IS3wnsXFmF2RKiyymPgC+zcmT6teDUqFfe2TQVpAijVCABTzVjsRJuzpw5ffv2rVNHNcOcE4tEQkYcHT5DjJ8v0+bDIQghtim1rJFFf1Wp14BERsZcHX61SpMhPsNIqTcPR6cZm+nJq6A7+wEAaCtIEQB4QYoAwAtSBABekCIA8IIUAYAXpAgAvCBFAOAFKQIAL0gRAHhBigDAC1IEAF6QIgDwghQBgBekCAC8IEUA4AUpAgAvSBEAeEGKAMALUgQAXpAiAPCCFAGAl8GlyN7enkLRkxEqgZYwuBR9+/ZNLpcTXQXQKwaXIgBUDlIEAF6QIgDwghQBgBekCAC8IEUA4AUpAgAvSBEAeEGKAMALUgQAXpAiAPCCFAGAF6QIALwgRQDgBSkCAC9IEQB4kZRKJdE1aEL79u0zMjLIZDL2eJVKJYlEatas2ebNm4kuDeg8Q2mL6tSpQyaTSSQSmUwmk8kUCsXe3n7UqFFE1wX0gaGkqH///vb29qXn+Pn51a5dm7iKgP4wlBT5+PjUqVOn5F9bW9vQ0FBCKwL6w1BShBAKDQ21s7PDpuvWrevj40N0RUBPGFCKfHx8fH19EUJ2dna9e/cmuhygPwwoRQihsLAwS0tLb29vLE4AqISWHulO+yRK/iDOShOLimSSYoVEpLIR5CRSKZVCIZNV8/HBsWaJ+VKWMcXUgmbnyvDwNTLiUFWyZqBDtCtFhTnSmEeF754WsrkMU2tjCo1CZVBodCpJawczJZHkxXJpsUwmVQjzRYI8oZEptU5zjndjU6IrA5qjLSkS8xWPL+akfBTaeFiwuCwyhUR0RVUk4kmEuXxetqBZV8vqfsZElwM0QStS9DVO+OJWAZPD5tiZEF2LakhEstykPGMOqfNwW6JrAWpHfIqibud/eCV09NXDdxs/W5idlDt4nitZa/dIgSoQnKK4Z4K3kUX2XlYE1qBWEqEs61N26DR7Gt2wDocaFCJf2rePCmOf8PU4QgghOptqW9P64NJkogsBakRYir59Fb1+wLOrZUlUARpDZVDsalqd3ZJOdCFAXQhKkRLdPpbt7GdHzNY1ztiCRaIx3zwoILoQoBbEpOjlrTy2GVt3D2dXgbkzN/JSDtFVALUgIEVKJXp+Pc/S3UzzmyYQiYRsPcyeXs0luhCgegSk6PW9fNtqXM1vt5Jev70xY0EjoZCn8jWbO3I+RPER8d/PARUjIEVfYoQsM6bmt0s4EoVEpVPSPouILgSomKZTJBEr8jKLjcxYGt6ulmBx2V/e8omuAqiYpn+AnPpJZOFkpL71Jya/uXVvb2p6vKmxZS3Ppq0DhzOZRgihg8dnUSi0mtUbX7y2USIRuTj7dmo7wdnRG7vX5etbomKuMujsur5tLc0d1VeeiZVRflae+tYPCKHptkhQIJNJ1XVoLjM7ae+hyXKZbOKofQNDl6d/+7DzwHiFQoEQolLpHz8/f5/weMrYQysWPqBSaafOhWP3evIi4smLsz06zpw8+oAZ1/bOgwNqKg8hRKWRM1Ngj07faDpF/EIZla6uX5VFx9ygUGiD+660sXK1s/Xo031+2rf49wmPEEIkEhkhFNZjoYW5A4VCrVM7JDP7a3GxECH0+OlpX+9g39qt2GzTRvW7uLvWVVN5CCEKjSyTKhRyOMKgVzSdIplESWfT1LTypJQYJ0cvI6MfBwDNzewtzB0Tk6Kxf62tXBkMNjbNYpoghIQinlKpzMlLtbF2K1mJo0MtNZWHsXRg8wtUdtIh0AYaPzGThKRimZrWLRLz078nzFjQqPTMoqIfX9FgzdEvxMUChULOZP48EYhOU+/xw7wMEdMIfpmqVzSdImMu5VuqulJkYmLhRvdr2+pfYzUasTnl3IXJMCKTKTJZccmcYolQTeUhhBRypVKJ6ExIkV7ReIpMqcpSb1nVsret/ib2VjW3eiTSjwMYGVmJVhbO5dyFRCKZce2SUmKbNw7D5sQnRKqpPISQTCJnm8DADPpG0x+KVk5MEU9dKWrZtL9cLrtwdYNEIs7MTrp8fcu6rf0yMr+Uf686tUNi4m6/jbuLELr78FDqt3g1lYcQEhUWWzkw1Ld+QAhNp8jMmkYmI4lQqo6VG7E5MyYcp9OYG3cOXrM5NDE5uk/3BQ72nuXfK6Tl0AZ1O527smbGgkbxH590bjsJIaRUKtRRoSBPUN1PjV+XAUIQcK7rg3M52VlkS5fyuiv6Kv5e0ohwNxoD+kV6hYCXs3ZjU3GhWPPbJVxRjsjV2xgipH8I6Ola2NHNrckF3/lcu7IHmvqe8XnbvtFl3kQmURTKsr9sadKwZ4fW41RVZFLK271HppZ5k1wuo5ApiFTGLzAa1e/aud2k360z81NO70kOqqoQaA9iRi8RFMqOrU6t0azso2cymZRXlF3mTUJREZtV9mhbDIZR+Qe1/1Re/rc/vQudzjY2Kvukj7z0ImOmpM0Aa1WUBrQLYWMARd0uSPkiN3fW3hONVEipQElRaUMWupTVgAGdR9g+un8Il0GT8jIERBWgSYkv0rqPs4cI6Ssie7odh9kqJAJelp4HKS02s80Aa66Vun49CAhH8PGibqPtRLm8/HTVn56tFZQo8UVaUC8zp+oGelaigSB+hGGE0O0TWYWFFK69KYWmP0eBCzIEGQk5faY4mtvSia4FqJdWpAgh9CGq6EFENtfOxNrDXNf7D4JccVZirrUjveNQW6TjjwVUhrakCBN1u+DTG75USjIyZ5taG9GYOjNKvEKuFBaIi7KF/FyBtTOzaScLS3toggyFdqUIk/pR9OkNPy9TlvFVQGNSWMY0rSvx/1gmVF62WCKWM9lUUwtqdT/jaj5Gxlz41bZh0cYUlSYskgt5ckmxlp4cSiaTWMYUtimVRoddN8Ol7SkCQPvpzzExAIgCKQIAL0gRAHhBigDAC1IEAF6QIgDw+h/XOemPDRrIKwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914b263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking chat agent with state: %s {'messages': [{'role': 'user', 'content': 'Hi, my name is abdo, and I want to ask you a question. Who is Alan Turing?'}], 'mode': 'chat'}\n",
      "Supervisor invoked with state: {'messages': [HumanMessage(content='Hi, my name is abdo, and I want to ask you a question. Who is Alan Turing?', additional_kwargs={}, response_metadata={}, id='d7a2a7eb-264e-41b2-ac0e-d6a79fbd887a')], 'mode': 'chat'}\n",
      "Chat run error: '__end__'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a28b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
