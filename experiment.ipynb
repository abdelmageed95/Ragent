{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbef0fd",
   "metadata": {},
   "source": [
    "### 1. RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a621312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pdf2image\n",
    "import PyPDF2\n",
    "from PIL import Image\n",
    "import cohere\n",
    "import logging\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "\n",
    "# --------------------------\n",
    "# Directory to save indices, metadata, and image previews\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Cohere client initialization\n",
    "co_client = cohere.ClientV2(api_key=\"SJcDVJBzLECN6S8mAT0SGbzx6PMUtFoyvHVQ5Kt0\")\n",
    "\n",
    "# --------------------------\n",
    "# Text Chunking\n",
    "# --------------------------\n",
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split a long text into overlapping chunks of approximately `chunk_size` words.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    logging.info(\"Chunking text into size %d with overlap %d\", chunk_size, overlap)\n",
    "    while start < len(words):\n",
    "        end = min(start + chunk_size, len(words))\n",
    "        chunks.append(\" \".join(words[start:end]))\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# --------------------------\n",
    "# PDF Handling\n",
    "# --------------------------\n",
    "def pdf_to_images(pdf_path: str) -> List[Image.Image]:\n",
    "    \"\"\"\n",
    "    Convert each page of a PDF file to a PIL Image.\n",
    "    \"\"\"\n",
    "    return pdf2image.convert_from_path(pdf_path, dpi=200)\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract raw text from a PDF using PyPDF2.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    logging.info(\"Extracting text from %s\", pdf_path)\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            txt = page.extract_text() or \"\"\n",
    "            if txt.strip():\n",
    "                texts.append(txt)\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "# --------------------------\n",
    "# Embedding Helpers\n",
    "# --------------------------\n",
    "def l2_normalize(vec: np.ndarray) -> np.ndarray:\n",
    "    norm = np.linalg.norm(vec)\n",
    "    return vec / norm if norm > 0 else vec\n",
    "\n",
    "\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get a normalized text embedding via Cohere embed-v4.0\n",
    "    \"\"\"\n",
    "    resp = co_client.embed(\n",
    "        model=\"embed-v4.0\",\n",
    "        input_type=\"search_document\",\n",
    "        embedding_types=[\"float\"],\n",
    "        texts=[text],\n",
    "    )\n",
    "    vec = np.array(resp.embeddings.float[0], dtype=np.float32)\n",
    "    return l2_normalize(vec)\n",
    "\n",
    "\n",
    "def embed_image(img: Image.Image) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get a normalized image embedding via Cohere embed-v4.0\n",
    "    \"\"\"\n",
    "    # Resize if too large\n",
    "    MAX_PIXELS = 1568 * 1568\n",
    "    if img.width * img.height > MAX_PIXELS:\n",
    "        scale = (MAX_PIXELS / (img.width * img.height)) ** 0.5\n",
    "        img = img.resize((int(img.width * scale), int(img.height * scale)))\n",
    "\n",
    "    # Convert to data URI\n",
    "    import base64\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")\n",
    "    b64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "    data_uri = f\"data:image/png;base64,{b64}\"\n",
    "\n",
    "    resp = co_client.embed(\n",
    "        model=\"embed-v4.0\",\n",
    "        input_type=\"search_document\",\n",
    "        embedding_types=[\"float\"],\n",
    "        inputs=[{\"content\": [{\"type\": \"image\", \"image\": data_uri}]}],\n",
    "    )\n",
    "    vec = np.array(resp.embeddings.float[0], dtype=np.float32)\n",
    "    return l2_normalize(vec)\n",
    "\n",
    "# --------------------------\n",
    "# Index Building             \n",
    "# --------------------------\n",
    "\n",
    "def build_and_save_indices(\n",
    "    pdf_paths: List[str],\n",
    "    text_index_path: str = os.path.join(data_dir, \"faiss_text.index\"),\n",
    "    image_index_path: str = os.path.join(data_dir, \"faiss_image.index\"),\n",
    "    text_meta_path: str = os.path.join(data_dir, \"text_docs_info.pkl\"),\n",
    "    image_meta_path: str = os.path.join(data_dir, \"image_docs_info.pkl\"),\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Build FAISS indices for text chunks and image pages, saving metadata. Each image preview is\n",
    "    saved to disk so it can later be passed to the LLM context.\n",
    "    \"\"\"\n",
    "    text_vectors, image_vectors = [], []\n",
    "    text_meta, image_meta = [], []\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        uid = str(uuid.uuid4())\n",
    "        filename = os.path.basename(pdf_path)\n",
    "\n",
    "        # --- Text chunks ---\n",
    "        raw_text = extract_text_from_pdf(pdf_path)\n",
    "        for i, chunk in enumerate(chunk_text(raw_text)):\n",
    "            vec = embed_text(chunk)\n",
    "            text_vectors.append(vec)\n",
    "            text_meta.append({\n",
    "                \"doc_id\": f\"{uid}_txt_{i}\",\n",
    "                \"source\": filename,\n",
    "                \"chunk\": i,\n",
    "                \"content\": chunk,\n",
    "            })\n",
    "\n",
    "        # --- Image pages ---\n",
    "        for page_num, img in enumerate(pdf_to_images(pdf_path), start=1):\n",
    "            vec = embed_image(img)\n",
    "            image_vectors.append(vec)\n",
    "            # Save a preview image to disk\n",
    "            preview_fname = f\"{uid}_img_{page_num}.png\"\n",
    "            preview_path = os.path.join(data_dir, preview_fname)\n",
    "            img.save(preview_path)\n",
    "\n",
    "            image_meta.append({\n",
    "                \"doc_id\": f\"{uid}_img_{page_num}\",\n",
    "                \"source\": filename,\n",
    "                \"page\": page_num,\n",
    "                \"preview_image\": preview_path,\n",
    "            })\n",
    "\n",
    "    # --- Persist FAISS indices and metadata ---\n",
    "    if text_vectors:\n",
    "        dim = text_vectors[0].shape[0]\n",
    "        idx_t = faiss.IndexFlatIP(dim)\n",
    "        idx_t.add(np.vstack(text_vectors))\n",
    "        faiss.write_index(idx_t, text_index_path)\n",
    "        with open(text_meta_path, \"wb\") as f:\n",
    "            pickle.dump(text_meta, f)\n",
    "        logging.info(\"Saved text index with %d vectors\", len(text_vectors))\n",
    "\n",
    "    if image_vectors:\n",
    "        dim = image_vectors[0].shape[0]\n",
    "        idx_i = faiss.IndexFlatIP(dim)\n",
    "        idx_i.add(np.vstack(image_vectors))\n",
    "        faiss.write_index(idx_i, image_index_path)\n",
    "        with open(image_meta_path, \"wb\") as f:\n",
    "            pickle.dump(image_meta, f)\n",
    "        logging.info(\"Saved image index with %d vectors\", len(image_vectors))\n",
    "\n",
    "# --------------------------\n",
    "# Loading Helpers\n",
    "# --------------------------\n",
    "\n",
    "def load_indices(\n",
    "    text_index_path: str = os.path.join(data_dir, \"faiss_text.index\"),\n",
    "    image_index_path: str = os.path.join(data_dir, \"faiss_image.index\"),\n",
    "    text_meta_path: str = os.path.join(data_dir, \"text_docs_info.pkl\"),\n",
    "    image_meta_path: str = os.path.join(data_dir, \"image_docs_info.pkl\"),\n",
    "):\n",
    "    \"\"\"Return (idx_text, text_meta, idx_img, image_meta).\"\"\"\n",
    "    idx_text, text_meta = None, []\n",
    "    idx_img, image_meta = None, []\n",
    "\n",
    "    if os.path.exists(text_index_path) and os.path.exists(text_meta_path):\n",
    "        idx_text = faiss.read_index(text_index_path)\n",
    "        with open(text_meta_path, \"rb\") as f:\n",
    "            text_meta = pickle.load(f)\n",
    "\n",
    "    if os.path.exists(image_index_path) and os.path.exists(image_meta_path):\n",
    "        idx_img = faiss.read_index(image_index_path)\n",
    "        with open(image_meta_path, \"rb\") as f:\n",
    "            image_meta = pickle.load(f)\n",
    "\n",
    "    return idx_text, text_meta, idx_img, image_meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aab243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built text index (27 vectors) and image index (109 vectors)\n"
     ]
    }
   ],
   "source": [
    "# pdf_folder = \"./pdfs\"\n",
    "# pdf_files = [os.path.join(pdf_folder, f) for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]\n",
    "# build_and_save_indices(pdf_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e756e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cohere\n",
    "from google import genai\n",
    "\n",
    "# -------------------------------\n",
    "# RAG Agent: Retrieval & LLM\n",
    "# -------------------------------\n",
    "\n",
    "class RagAgent:\n",
    "    \"\"\"\n",
    "    RAG Agent that handles multimodal retrieval (text + image) from separate FAISS indices,\n",
    "    and can query Gemini for direct answers via the google-genai client.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        text_index_path: str = os.path.join(\"data\", \"faiss_text.index\"),\n",
    "        image_index_path: str = os.path.join(\"data\", \"faiss_image.index\"),\n",
    "        text_meta_path: str = os.path.join(\"data\", \"text_docs_info.pkl\"),\n",
    "        image_meta_path: str = os.path.join(\"data\", \"image_docs_info.pkl\"),\n",
    "    ) -> None:\n",
    "        # Load FAISS indices and metadata\n",
    "        self.idx_text, self.text_meta, self.idx_img, self.image_meta = load_indices(\n",
    "            text_index_path, image_index_path, text_meta_path, image_meta_path\n",
    "        )\n",
    "\n",
    "        # Cohere client for embeddings\n",
    "        self.co_client = cohere.ClientV2(api_key=\"SJcDVJBzLECN6S8mAT0SGbzx6PMUtFoyvHVQ5Kt0\")\n",
    "\n",
    "        # google-genai client for LLM generation\n",
    "        self.genai_client = genai.Client(api_key=\"AIzaSyDoElOZE1wayqlHYGaTNh_uAc2QRgjs85Q\")\n",
    "\n",
    "    def embed_query(self, query: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Embed the user query into the shared vector space.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            resp = self.co_client.embed(\n",
    "                model=\"embed-v4.0\",\n",
    "                input_type=\"search_query\",\n",
    "                embedding_types=[\"float\"],\n",
    "                texts=[query],\n",
    "            )\n",
    "            vec = np.array(resp.embeddings.float[0], dtype=np.float32)\n",
    "            return l2_normalize(vec)\n",
    "        except Exception as e:\n",
    "            print(f\"Query embedding error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def retrieve(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k_text: int = 5,\n",
    "        top_k_image: int = 5,\n",
    "        top_n: int = 3,\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform multimodal retrieval: query both text and image FAISS indices,\n",
    "        fuse and re-rank results, and return top_n entries.\n",
    "\n",
    "        Each hit dict contains: doc_id, source, modality, chunk/page, score, content/preview.\n",
    "        \"\"\"\n",
    "        q_vec = self.embed_query(query)\n",
    "        if q_vec is None:\n",
    "            return []\n",
    "\n",
    "        all_hits: List[Dict[str, Any]] = []\n",
    "        # --- Text retrieval ---\n",
    "        if self.idx_text:\n",
    "            D_t, I_t = self.idx_text.search(np.array([q_vec]), top_k_text)\n",
    "            for score, idx in zip(D_t[0], I_t[0]):\n",
    "                if idx < len(self.text_meta):\n",
    "                    meta = self.text_meta[idx]\n",
    "                    all_hits.append({\n",
    "                        \"doc_id\": meta[\"doc_id\"],\n",
    "                        \"source\": meta[\"source\"],\n",
    "                        \"modality\": \"text\",\n",
    "                        \"chunk\": meta.get(\"chunk\"),\n",
    "                        \"score\": float(score),\n",
    "                        \"content\": meta.get(\"content\"),\n",
    "                    })\n",
    "        # --- Image retrieval ---\n",
    "        if self.idx_img:\n",
    "            D_i, I_i = self.idx_img.search(np.array([q_vec]), top_k_image)\n",
    "            for score, idx in zip(D_i[0], I_i[0]):\n",
    "                if idx < len(self.image_meta):\n",
    "                    meta = self.image_meta[idx]\n",
    "                    all_hits.append({\n",
    "                        \"doc_id\": meta[\"doc_id\"],\n",
    "                        \"source\": meta[\"source\"],\n",
    "                        \"modality\": \"image\",\n",
    "                        \"page\": meta.get(\"page\"),\n",
    "                        \"score\": float(score),\n",
    "                        \"preview\": meta.get(\"preview_image\"),\n",
    "                    })\n",
    "        # --- Fuse & re-rank ---\n",
    "        sorted_hits = sorted(all_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "        return sorted_hits[:top_n]\n",
    "\n",
    "    def generate_answer(\n",
    "        self,\n",
    "        question: str,\n",
    "        context: Dict[str, Any],\n",
    "        use_image: bool = False,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Use google-genai to generate an answer given either text content or an image preview.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if use_image and context.get(\"preview\"):\n",
    "                img = Image.open(context[\"preview\"])\n",
    "                prompt = [\n",
    "                    f\"Answer the question based on the following image.\\nDon't use markdown.\\nPlease provide enough context.\\n\\nQuestion: {question}\",\n",
    "                    img,\n",
    "                ]\n",
    "                response = self.genai_client.models.generate_content(\n",
    "                    model=\"gemini-2.5-flash\",\n",
    "                    contents=prompt\n",
    "                )\n",
    "            else:\n",
    "                text = context.get(\"content\", \"\")\n",
    "                prompt = [\n",
    "                    f\"Answer the question based on the following information.\\nDon't use markdown.\\nPlease provide enough context.\\n\\nInformation: {text}\\nQuestion: {question}\"\n",
    "                ]\n",
    "                response = self.genai_client.models.generate_content(\n",
    "                    model=\"gemini-2.5-flash\",\n",
    "                    contents=[prompt[0]]  # Pass a list of one string\n",
    "                )\n",
    "            if response.text is not None:\n",
    "                return response.text.strip()\n",
    "            else:\n",
    "                return \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"Gemini generation error: {e}\")\n",
    "            return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32812f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "# load from env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def rag_answer(query, top_k_text=5, top_k_image=5, top_n=3):\n",
    "    \"\"\"\n",
    "    Generate a coherent answer to the given query by retrieving relevant text and image data,\n",
    "    generating candidate answers, and then selecting the best one using a language model.\n",
    "    \"\"\"\n",
    "    agent = RagAgent()\n",
    "    hits = agent.retrieve(query, top_k_text=top_k_text, top_k_image=top_k_image, top_n=top_n)\n",
    "    for h in hits:\n",
    "        modality = h['modality'].upper()\n",
    "        print(f\"[{modality}] {h['score']:.3f} — {h['source']} (ID: {h['doc_id']})\")\n",
    "    concat_ans= []\n",
    "    for h in hits:\n",
    "        ans = agent.generate_answer(query,\n",
    "                                    h,\n",
    "                                    use_image=(h['modality']=='image')\n",
    "                                    )\n",
    "        concat_ans.append(ans)\n",
    "        \n",
    "    msg = [\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":f\"\"\"you are a helpful assistant who can decide and select the right answer among \n",
    "            multiple answers for the given question.\n",
    "            here is the question: {query} \\n\\n\n",
    "            candidate answers: {concat_ans} \\n\n",
    "\n",
    "            - If you find that more than one answer is correct and complement to each other,combine them\n",
    "            into one coherent and well organized answer.\n",
    "\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages= msg,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    fans= res.choices[0].message.content\n",
    "    return fans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90de9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_agent.ragagent import rag_answer, RagAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445495dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEXT] 0.336 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_36)\n",
      "[IMAGE] 0.330 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_img_65)\n",
      "[TEXT] 0.324 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_38)\n",
      "The breakdown of the Consolidated Income Statement values for the periods 1 January 2023 – 31 December 2023 and 1 January 2022 – 31 December 2022, presented in KSEK, is as follows:\n",
      "\n",
      "**For the period 1 January 2023 – 31 December 2023:**\n",
      "\n",
      "- **Operating Income:**\n",
      "  - Net sales: 60,534 KSEK\n",
      "  - Capitalized amount for own accounts: 20,944 KSEK\n",
      "  - Other operating income: -1,170 KSEK\n",
      "  - **Total Operating Income: 80,308 KSEK**\n",
      "\n",
      "- **Operating Expenses:**\n",
      "  - Other external costs: -50,112 KSEK\n",
      "  - Personnel costs: -88,419 KSEK\n",
      "  - Depreciation and amortization on fixed assets: -14,204 KSEK\n",
      "  - Other operating expenses: -2 KSEK\n",
      "  - **Operating Profit: -72,430 KSEK**\n",
      "\n",
      "- **Result from Financial Items:**\n",
      "  - Interest income and similar items: 35,292 KSEK\n",
      "  - Interest expenses and similar items: -20,866 KSEK\n",
      "  - **Profit After Financial Items: -58,001 KSEK**\n",
      "\n",
      "- **Tax on Profit for the Year: 0 KSEK**\n",
      "- **Net Profit for the Year: -58,001 KSEK**\n",
      "\n",
      "---\n",
      "\n",
      "**For the period 1 January 2022 – 31 December 2022:**\n",
      "\n",
      "- **Operating Income:**\n",
      "  - Net sales: 45,678 KSEK\n",
      "  - Capitalized amount for own accounts: 13,178 KSEK\n",
      "  - Other operating income: 5,842 KSEK\n",
      "  - **Total Operating Income: 64,698 KSEK**\n",
      "\n",
      "- **Operating Expenses:**\n",
      "  - Other external costs: -55,438 KSEK\n",
      "  - Personnel costs: -85,460 KSEK\n",
      "  - Depreciation and amortization on fixed assets: -12,689 KSEK\n",
      "  - Other operating expenses: (blank value, implies 0 or insignificant)\n",
      "  - **Operating Profit: -88,890 KSEK**\n",
      "\n",
      "- **Result from Financial Items:**\n",
      "  - Interest income and similar items: 37,542 KSEK\n",
      "  - Interest expenses and similar items: -33,767 KSEK\n",
      "  - **Profit After Financial Items: -85,115 KSEK**\n",
      "\n",
      "- **Tax on Profit for the Year: -246 KSEK**\n",
      "- **Net Profit for the Year: -85,362 KSEK**\n",
      "\n",
      "---\n",
      "\n",
      "It is important to note that while the above provides a detailed breakdown of the Consolidated Income Statement values, the information provided does not include a specific list of line items or categories that would typically constitute the \"breakdown\" of the Consolidated Income Statement, such as revenue, cost of sales, and operating expenses. Additionally, the document discusses accounting principles, consolidation methods, and the handling of foreign currency transactions, but does not provide a comprehensive breakdown of the Consolidated Income Statement values.\n"
     ]
    }
   ],
   "source": [
    "# query = \"what is the Consolidated Income Statement values breakdown?\"\n",
    "# ans = rag_answer(query)\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk #5 content:\n",
      "\n",
      "service by at least 40%. We make customer service automation and the agentless contact centers possible. Our focus remains on empowering enterprises, fostering growth, and setting new benchmarks for success . Artificial Solutions.com or Teneo.ai ®? We started a transition in our go -to-market branding during last year and now all our customer facing material is on Teneo.ai. Furthermore, our sales organization are contacting prospects from Teneo.ai. This has proven positive for our market recognition a nd we want to take the next step in this direction and change the name of our company as well to Teneo.ai. We will therefore evaluate a potential change of the company name as well to Teneo.ai in the coming months. . Artiﬁcial Solutions - Annual Report 2023 11 How We Generate Our Revenues A Highly Scalable Revenue Model Artiﬁcial Solutions has a highly scalable and sticky subscription -based business model where the company's recurring revenues scale with its customers increased usage of the Teneo platform or its solutions powered by Teneo.ai. Accordingly, volume on our A PI calls, the time our customers’ customers use the platform drive our success. This is opposite to most other SaaS companies. Most other SaaS companies are dependent on the number of users using their SaaS software rather than the amount (volume) they use them. The revenue streams in the SaaS model consists of the categories: 1. Subscription revenues from Teneo – based on number of users. 2. API calls generated in Teneo Engine – based on number of API calls (volume -linked). 3. Teneo Data – analytics platform to review users’ conversations and enhance the conversational AI solutions. Revenues based on ingested data. The three ﬁrst revenues (#1- 3) above represent recurring SaaS revenues and constituted 99% of our revenues 2023, which are part of our total recurring revenues and our ARR metric. The remaining revenues, approximately 1% of our revenues 2023, is related t o expert services, which is not a focus for our strategy. F r o m t h e ﬁ r s t q u a r t e r 2 0 2 4 , A r t i ﬁ c a l S o l u t i o n s a l s o p r o v i d e a p r o v e r s i o n o f T e n e o , w h i c h i s suitable for small to midsized companies. The subscription fee is lower than for the enterprise version (shown below) while the API call fee per API call is the same (0.008 USD per API call). The key revenue streams are: During the ﬁrst quarter 2024, the API call revenues (volume -linked) constituted to 60% of our total revenues, up from 53% in 2023, which highlights the essence in our revenue model – growth in volumes in API calls is the most important for our growth and with growth in API calls our gross margin expands.\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 1) Load your text‐chunk metadata\n",
    "# with open(\"data/text_docs_info.pkl\", \"rb\") as f:\n",
    "#     text_meta = pickle.load(f)\n",
    "\n",
    "# # 2) Find the entry whose doc_id ends with “_txt_5”\n",
    "# for entry in text_meta:\n",
    "#     if entry[\"doc_id\"].endswith(\"_txt_5\"):\n",
    "#         print(\"Chunk #5 content:\\n\")\n",
    "#         print(entry[\"content\"])\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f1f90",
   "metadata": {},
   "source": [
    "### 2. Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a45b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant as LCQdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qdrant_models\n",
    "from pymongo import MongoClient, ReturnDocument\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ---------------------------\n",
    "# Memory Configuration\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class MemoryConfig:\n",
    "    # Qdrant settings (for long-term vector memory)\n",
    "    qdrant_url: str = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "    qdrant_api_key: Optional[str] = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "    # MongoDB settings (for structured facts & message history)\n",
    "    mongo_uri: str = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "    db_name: str = os.getenv(\"MONGO_DB\", \"agentic_memory\")\n",
    "\n",
    "    # Short-term buffer size (user+assistant turns)\n",
    "    short_term_window: int = int(os.getenv(\"SHORT_TERM_WINDOW\", \"6\"))\n",
    "\n",
    "    # Embeddings model for long-term memory\n",
    "    embeddings: OpenAIEmbeddings = field(\n",
    "        default_factory=lambda: OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    )\n",
    "\n",
    "# ---------------------------\n",
    "# Memory Agent\n",
    "# ---------------------------\n",
    "class MemoryAgent:\n",
    "    \"\"\"\n",
    "    Agentic memory manager handling:\n",
    "      - Short-term conversational context (in-memory)\n",
    "      - Long-term semantic memory (Qdrant)\n",
    "      - Structured user facts (MongoDB using LLM extraction)\n",
    "      - Persistent message history for UI pagination (MongoDB)\n",
    "\n",
    "    Uses OpenAI text-embedding-3-small for long-term embeddings and GPT-4o Mini to extract facts.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_id: str,\n",
    "        thread_id: str,\n",
    "        cfg: Optional[MemoryConfig] = None,\n",
    "    ) -> None:\n",
    "        self.user_id = str(user_id)\n",
    "        self.thread_id = str(thread_id)\n",
    "        self.cfg = cfg or MemoryConfig()\n",
    "\n",
    "        # ----- Qdrant long-term memory -----\n",
    "        self.qdrant_client = QdrantClient(\n",
    "            url=self.cfg.qdrant_url,\n",
    "            api_key=self.cfg.qdrant_api_key\n",
    "        )\n",
    "      \n",
    "        self.collection_name = f\"mem_{self.user_id}_{self.thread_id}\"\n",
    "        self._ensure_qdrant_collection()\n",
    "        self.qdrant_store = LCQdrant(\n",
    "            client=self.qdrant_client,\n",
    "            collection_name=self.collection_name,\n",
    "            embeddings=self.cfg.embeddings,\n",
    "        )\n",
    "\n",
    "        # ----- MongoDB structured facts & history -----\n",
    "        self.mongo = MongoClient(self.cfg.mongo_uri)\n",
    "        self.mongo_db = self.mongo[self.cfg.db_name]\n",
    "        self.facts_col = self.mongo_db[\"user_facts\"]\n",
    "        self.messages_col = self.mongo_db[\"messages_history\"]\n",
    "\n",
    "        # ----- In-memory short-term buffer -----\n",
    "        self._short_term: List[Dict[str, str]] = []\n",
    "\n",
    "    def _ensure_qdrant_collection(self) -> None:\n",
    "        \"\"\"Create the Qdrant collection if it does not exist.\"\"\"\n",
    "        if not self.qdrant_client.collection_exists(self.collection_name):\n",
    "            dim = len(self.cfg.embeddings.embed_query(\"test query\"))\n",
    "            self.qdrant_client.create_collection(\n",
    "                collection_name=self.collection_name,\n",
    "                vectors_config=qdrant_models.VectorParams(\n",
    "                    size=dim,\n",
    "                    distance=qdrant_models.Distance.COSINE,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def fetch_short_term(self) -> List[Dict[str,Any]]:\n",
    "        # pull the last N messages from Mongo instead of the in‑memory list\n",
    "        cursor = self.messages_col.find(\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id}\n",
    "        ).sort(\"timestamp\", -1).limit(self.cfg.short_term_window * 2)\n",
    "        # reverse so oldest→newest\n",
    "        return list(cursor)[::-1]\n",
    "\n",
    "\n",
    "    def fetch_history(\n",
    "        self,\n",
    "        page: int = 0,\n",
    "        page_size: int = 50\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Return paginated conversation history.\"\"\"\n",
    "        skip = page * page_size\n",
    "        cursor = self.messages_col.find(\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id}\n",
    "        ).sort(\"timestamp\", 1).skip(skip).limit(page_size)\n",
    "        return list(cursor)\n",
    "\n",
    "    def fetch_long_term(\n",
    "        self,\n",
    "        query: Optional[str] = None,\n",
    "        k: int = 5,\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Semantic recall of past conversation turns.\"\"\"\n",
    "        if query is None and self._short_term and self._short_term[-1][\"role\"] == \"user\":\n",
    "            query = self._short_term[-1][\"content\"]\n",
    "        if not query:\n",
    "            return []\n",
    "        return self.qdrant_store.similarity_search(query, k=k)\n",
    "\n",
    "    def get_user_facts(self) -> Dict[str, Any]:\n",
    "        \"\"\"Retrieve the deduplicated facts dictionary for this user.\"\"\"\n",
    "        doc = self.facts_col.find_one({\"user_id\": self.user_id}) or {}\n",
    "        # 'facts' is stored as a dict; return it directly\n",
    "        return doc.get(\"facts\", {})\n",
    "\n",
    "    def update(self, user_message: str, assistant_message: str) -> None:\n",
    "        \"\"\"\n",
    "        Append new messages, persist history, long-term memory, and update facts.\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now()\n",
    "\n",
    "        # 1) Short-term buffer\n",
    "        self._short_term.append({\"role\": \"user\", \"content\": user_message})\n",
    "        self._short_term.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        excess = len(self._short_term) - (self.cfg.short_term_window * 2)\n",
    "        if excess > 0:\n",
    "            self._short_term = self._short_term[excess:]\n",
    "\n",
    "        # 2) Persist messages\n",
    "        self.messages_col.insert_many([\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id, \"role\": \"user\", \"content\": user_message, \"timestamp\": timestamp},\n",
    "            {\"user_id\": self.user_id, \"thread_id\": self.thread_id, \"role\": \"assistant\", \"content\": assistant_message, \"timestamp\": timestamp},\n",
    "        ])\n",
    "\n",
    "        # 3) Persist long-term memory\n",
    "        combined = f\"User: {user_message}\\nAssistant: {assistant_message}\"\n",
    "        doc = Document(page_content=combined, metadata={\n",
    "            \"user_id\": self.user_id,\n",
    "            \"thread_id\": self.thread_id,\n",
    "            \"timestamp\": timestamp.isoformat(),\n",
    "        })\n",
    "        self.qdrant_store.add_documents([doc])\n",
    "\n",
    "        # 4) Merge and update facts\n",
    "        existing = self.get_user_facts()  # existing dict\n",
    "        new = self.extract_facts(user_message) or {}\n",
    "        merged = {**existing, **new}\n",
    "        if merged:\n",
    "            self.facts_col.update_one(\n",
    "                {\"user_id\": self.user_id},\n",
    "                {\"$set\": {\"facts\": merged, \"last_update\": timestamp}},\n",
    "                upsert=True,\n",
    "            )\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_facts(text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Use an LLM (GPT-4o Mini) to extract personal/info facts from text.\n",
    "        Returns a dict of key/value pairs.\n",
    "        \"\"\"\n",
    "        prompt = (\n",
    "            \"Extract any personal profile information and relevant facts from the following text. \"\n",
    "            \"Return ONLY a JSON object with key/value pairs, no additional text, no explanations.\"\n",
    "             \"If there is no relevant information in the text, return an empty object.\\n\\n\"\n",
    "            f\"Text: {text}\"\n",
    "        )\n",
    "        try:\n",
    "            resp = openai_client.chat.completions.create(\n",
    "                model = \"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an assistant that extracts personal user information as JSON.\"},\n",
    "                    {\"role\": \"user\",   \"content\": prompt},\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            content = resp.choices[0].message.content.strip()\n",
    "            return json.loads(content)\n",
    "        except Exception as e:\n",
    "            print(f\"Fact extraction error: {e}\")\n",
    "            return {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28fd950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('687c13639c13940e547c5e98'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'assistant', 'content': [\"I'm doing well, thanks for asking!\"], 'timestamp': datetime.datetime(2025, 7, 20, 0, 51, 31, 318000)}, {'_id': ObjectId('687c13639c13940e547c5e97'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'user', 'content': [\"Hi, I'm Jane Doe from Boston. My email is jane@example.com and I love hiking.\"], 'timestamp': datetime.datetime(2025, 7, 20, 0, 51, 31, 318000)}, {'_id': ObjectId('687c139f9c13940e547c5e9b'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'assistant', 'content': ['this is amazing!'], 'timestamp': datetime.datetime(2025, 7, 20, 0, 52, 31, 304000)}, {'_id': ObjectId('687c139f9c13940e547c5e9a'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'user', 'content': ['i went to saft elsharkia school in 2000'], 'timestamp': datetime.datetime(2025, 7, 20, 0, 52, 31, 304000)}, {'_id': ObjectId('687c15549c13940e547c5e9e'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'assistant', 'content': ['this is amazing!'], 'timestamp': datetime.datetime(2025, 7, 20, 0, 59, 48, 967000)}, {'_id': ObjectId('687c15549c13940e547c5e9d'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'user', 'content': ['i went to saft elsharkia school in 2000'], 'timestamp': datetime.datetime(2025, 7, 20, 0, 59, 48, 967000)}, {'_id': ObjectId('687c15869c13940e547c5ea1'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'assistant', 'content': ['this is amazing!'], 'timestamp': datetime.datetime(2025, 7, 20, 1, 0, 38, 649000)}, {'_id': ObjectId('687c15869c13940e547c5ea0'), 'user_id': 'abdo', 'thread_id': 'session1', 'role': 'user', 'content': ['i went to saft elsharkia school in 2000'], 'timestamp': datetime.datetime(2025, 7, 20, 1, 0, 38, 649000)}]\n",
      "[Document(metadata={'user_id': 'abdo', 'thread_id': 'session1', 'timestamp': '2025-07-20T00:51:31.318846', '_id': '7d595a9b-008b-4ba4-9852-14bb89b805ee', '_collection_name': 'mem_abdo_session1'}, page_content='User: (\"Hi, I\\'m Jane Doe from Boston. My email is jane@example.com and I love hiking.\",)\\nAssistant: (\"I\\'m doing well, thanks for asking!\",)'), Document(metadata={'user_id': 'abdo', 'thread_id': 'session1', 'timestamp': '2025-07-20T00:52:31.304009', '_id': '74c4a995-7f7a-4c27-b436-e688bb9c782e', '_collection_name': 'mem_abdo_session1'}, page_content=\"User: ('i went to saft elsharkia school in 2000',)\\nAssistant: ('this is amazing!',)\"), Document(metadata={'user_id': 'abdo', 'thread_id': 'session1', 'timestamp': '2025-07-20T01:00:38.649961', '_id': 'c95c6b0d-a729-488f-abd6-74ff191ea4a7', '_collection_name': 'mem_abdo_session1'}, page_content=\"User: ('i went to saft elsharkia school in 2000',)\\nAssistant: ('this is amazing!',)\"), Document(metadata={'user_id': 'abdo', 'thread_id': 'session1', 'timestamp': '2025-07-20T00:59:48.967436', '_id': '51402d5c-72dd-40a2-9299-5c98a418557d', '_collection_name': 'mem_abdo_session1'}, page_content=\"User: ('i went to saft elsharkia school in 2000',)\\nAssistant: ('this is amazing!',)\")]\n",
      "{'name': 'Jane Doe', 'location': 'Boston', 'email': 'jane@example.com', 'hobbies': ['hiking'], 'school': 'saft elsharkia school', 'year_attended': 2000}\n"
     ]
    }
   ],
   "source": [
    "# user_msg=\"i went to saft elsharkia school in 2000\",\n",
    "# assistant_msg=\"this is amazing!\",\n",
    "# mem = MemoryAgent(user_id=\"abdo\", thread_id=\"session1\")\n",
    "# mem.update(\n",
    "#    user_message=user_msg,\n",
    "#    assistant_message=assistant_msg\n",
    "# )\n",
    "# print(mem.fetch_short_term())\n",
    "# print(mem.fetch_long_term(query=\"Alice?\"))\n",
    "# print(mem.get_user_facts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c91330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': (\"Hi, I'm Jane Doe from Boston. My email is jane@example.com and I love hiking.\",)}, {'role': 'assistant', 'content': (\"I'm doing well, thanks for asking!\",)}]\n",
      "[Document(metadata={'user_id': 'abdo', 'thread_id': 'session1', 'timestamp': '2025-07-20T00:51:31.318846', '_id': '7d595a9b-008b-4ba4-9852-14bb89b805ee', '_collection_name': 'mem_abdo_session1'}, page_content='User: (\"Hi, I\\'m Jane Doe from Boston. My email is jane@example.com and I love hiking.\",)\\nAssistant: (\"I\\'m doing well, thanks for asking!\",)')]\n",
      "{'name': 'Jane Doe', 'location': 'Boston', 'email': 'jane@example.com', 'hobbies': ['hiking']}\n"
     ]
    }
   ],
   "source": [
    "# user_msg=\"Hi, I'm Jane Doe from Boston. My email is jane@example.com and I love hiking.\",\n",
    "# assistant_msg=\"I'm doing well, thanks for asking!\",\n",
    "# mem = MemoryAgent(user_id=\"abdo\", thread_id=\"session1\")\n",
    "# mem.update(\n",
    "#    user_message=user_msg,\n",
    "#    assistant_message=assistant_msg\n",
    "# )\n",
    "# print(mem.fetch_short_term())\n",
    "# print(mem.fetch_long_term(query=\"Alice?\"))\n",
    "# print(mem.get_user_facts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c7436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Import modules for chatbot diagram\n",
    "# from IPython.display import Image, display\n",
    "# # Try generating and displaying\n",
    "# # the graph diagram\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# # Return an exception if necessary\n",
    "# except Exception:\n",
    "#     print(\"Additional dependencies required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0vXtCplPRLuJMB1oStvLKcxV', 'function': {'arguments': '{\"query\":\"Mary Shelley\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 86, 'total_tokens': 100, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BvNlqjTScBY464Jh5ZJ20fZBu7PLd', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c187764e-f624-4a50-91fd-5213d60e5c93-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Mary Shelley'}, 'id': 'call_0vXtCplPRLuJMB1oStvLKcxV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 14, 'total_tokens': 100, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: [ToolMessage(content=\"Page: Mary Shelley\\nSummary: Mary Wollstonecraft Shelley (UK:  WUUL-stən-krahft, US:  -\\u2060kraft; née Godwin; 30 August 1797 – 1 February 1851) was an English novelist who wrote the Gothic novel Frankenstein; or, The Modern Prometheus (1818), which is considered an early example of science fiction. She also edited and promoted the works of her husband, the Romantic poet and philosopher Percy Bysshe Shelley. Her father was the political philosopher William Godwin and her mother was the philosopher and women's rights advocate Mary Wollstonecraft.\\nMary's mother died 11 days after giving birth to her. She was raised by her father, who provided her with a rich informal education, encouraging her to adhere to his own anarchist political theories. When she was four, her father married a neighbour, Mary Jane Clairmont, with whom Mary had a troubled relationship.\\nIn 1814, Mary began a romance with one of her father's political followers, Percy Bysshe Shelley, who was already married. Together with her stepsister, Claire Clairmont, she and Percy left for France and travelled through Europe. Upon their return to England, Mary was pregnant with Percy's child. Over the next two years, she and Percy faced ostracism, constant debt and the death of their prematurely born daughter. They married in late 1816, after the suicide of Percy Shelley's wife, Harriet.\\nIn 1816, the couple and Mary's stepsister famously spent a summer with Lord Byron and John William Polidori near Geneva, Switzerland, where Shelley conceived the idea for her novel Frankenstein. The Shelleys left Britain in 1818 for Italy, where their second and third children died before Shelley gave birth to her last and only surviving child, Percy Florence Shelley. In 1822, her husband drowned when his sailboat sank during a storm near Viareggio. A year later, Shelley returned to England and from then on devoted herself to raising her son and her career as a professional author. The last decade of her life was dogged by illness, most likely caused by the brain tumour which killed her at the age of 53.\\nUntil the 1970s, Shelley was known mainly for her efforts to publish her husband's works and for her novel Frankenstein, which remains widely read and has inspired many theatrical and film adaptations. Recent scholarship has yielded a more comprehensive view of Shelley's achievements. Scholars have shown increasing interest in her literary output, particularly in her novels, which include the historical novels Valperga (1823) and Perkin Warbeck (1830), the apocalyptic novel The Last Man (1826) and her final two novels, Lodore (1835) and Falkner (1837). Studies of her lesser-known works, such as the travel book Rambles in Germany and Italy (1844) and the biographical articles for Dionysius Lardner's Cabinet Cyclopaedia (1829–1846), support the growing view that Shelley remained a political radical throughout her life. Shelley's works often argue that cooperation and sympathy, particularly as practised by women in the family, were the ways to reform civil society. This view was a direct challenge to the individualistic Romantic ethos promoted by Percy Shelley and the Enlightenment political theories articulated by her father, William Godwin.\\n\\n\", name='wikipedia', id='e58ee252-b1a8-4ccb-a9f4-ff8823bbd351', tool_call_id='call_0vXtCplPRLuJMB1oStvLKcxV')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: [AIMessage(content='Mary Wollstonecraft Shelley (30 August 1797 – 1 February 1851) was an English novelist best known for her Gothic novel \"Frankenstein; or, The Modern Prometheus\" (1818), which is considered an early example of science fiction. She was the daughter of the political philosopher William Godwin and the women\\'s rights advocate Mary Wollstonecraft, who died shortly after giving birth to her.\\n\\nMary Shelley had a turbulent upbringing, raised by her father and later facing challenges with her stepmother. In 1814, she began a romance with Percy Bysshe Shelley, a married man and one of her father\\'s political followers. Their relationship led to social ostracism and personal tragedies, including the death of their first child. They married in 1816 after the suicide of Percy\\'s first wife.\\n\\nThe idea for \"Frankenstein\" was conceived during a summer spent with Lord Byron and John William Polidori in Switzerland. Following a series of personal losses, including the deaths of her children and the drowning of Percy in 1822, Mary returned to England to focus on her writing and raising her surviving son, Percy Florence Shelley.\\n\\nThough initially known mainly for \"Frankenstein\" and her role in promoting her husband\\'s work, recent scholarship has highlighted her literary contributions, including other novels like \"Valperga,\" \"The Last Man,\" and \"Lodore.\" Shelley\\'s works often reflect her political radicalism and emphasize cooperation and sympathy, particularly among women, as means to reform society. She died at the age of 53, likely due to a brain tumor.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 323, 'prompt_tokens': 794, 'total_tokens': 1117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BvNltUxsgLUha9Nnf9u7oN72oeZQf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fdcd6055-7b5a-487f-adae-2f3edf54d947-0', usage_metadata={'input_tokens': 794, 'output_tokens': 323, 'total_tokens': 1117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# # Define a function to execute the chatbot based on user input\n",
    "# def stream_graph_updates(user_input: str):\n",
    "#     # Start streaming events from the graph with the user's input\n",
    "#     for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "#         # Retrieve and print the chatbot node responses\n",
    "#         for value in event.values():\n",
    "#             print(\"Agent:\", value[\"messages\"])\n",
    "# # Define the user query and run the chatbot\n",
    "# user_query = \"Who is Mary Shelley?\"\n",
    "# stream_graph_updates(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a230dc",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10de7385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LangGraph Multi-Agent System with Wikipedia ===\n",
      "\n",
      "================================================================================\n",
      "👤 User: elaborate the consolidate income statement\n",
      "\n",
      "🚀 LangGraph Workflow: elaborate the consolidate income statement...\n",
      "📚 Memory Fetch Node: Loading context...\n",
      "✅ Memory loaded: 20 recent, 5 relevant, 3 facts\n",
      "🧠 Supervisor Node: Making routing decision...\n",
      "🎯 Supervisor decision: rag_agent\n",
      "🔍 RAG Agent Node: Processing document search...\n",
      "Loading indices from data/faiss_text.index and data/faiss_image.index with metadata from data/text_docs_info.pkl and data/image_docs_info.pkl\n",
      "[TEXT] 0.351 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_36)\n",
      "[TEXT] 0.347 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_38)\n",
      "[TEXT] 0.322 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_35)\n",
      "💾 Memory Update Node: Saving conversation...\n",
      "✅ Memory updated successfully\n",
      "🎉 LangGraph Workflow completed\n",
      "\n",
      "🤖 Agent (rag_agent): The Consolidated Income Statement provides a comprehensive overview of the financial performance of the parent company and all its subsidiaries over a specific period, specifically for the years 2023 and 2022. All amounts are presented in thousand Swedish Krona (KSEK).\n",
      "\n",
      "### Key Components of the Consolidated Income Statement:\n",
      "\n",
      "1. **Operating Income:**\n",
      "   - **Net Sales:** This represents the primary revenue generated from the company's core operations. For 2023, net sales were 60,534 KSEK, a significant increase from 45,678 KSEK in 2022, indicating growth in sales.\n",
      "   - **Capitalized Amount for Own Accounts:** This refers to costs incurred for internal development projects that are capitalized rather than expensed immediately. This amount increased from 13,178 KSEK in 2022 to 20,944 KSEK in 2023, suggesting increased internal development activities.\n",
      "   - **Other Operating Income:** This includes revenue from activities not directly related to core sales. It was 5,842 KSEK in 2022 but turned negative at -1,170 KSEK in 2023, possibly due to losses on asset disposals or negative adjustments.\n",
      "   - **Total Operating Income:** The sum of the above items increased from 64,698 KSEK in 2022 to 80,308 KSEK in 2023, primarily driven by growth in net sales and capitalized own accounts.\n",
      "\n",
      "2. **Operating Expenses:**\n",
      "   - **Other External Costs:** These costs for services or goods purchased from external parties decreased from -55,438 KSEK in 2022 to -50,112 KSEK in 2023, indicating improved cost efficiency.\n",
      "   - **Personnel Costs:** These expenses related to employee salaries and benefits increased from -85,460 KSEK in 2022 to -88,419 KSEK in 2023, likely due to increased headcount or salary adjustments.\n",
      "   - **Depreciation and Amortization:** This increased from -12,689 KSEK in 2022 to -14,204 KSEK in 2023, aligning with increased capitalized development efforts and potentially new assets.\n",
      "   - **Other Operating Expenses:** This line item was zero for both years.\n",
      "\n",
      "3. **Operating Profit:** The company incurred an operating loss in both years, but the loss decreased from -88,890 KSEK in 2022 to -72,430 KSEK in 2023, indicating improved operational efficiency despite higher personnel costs and depreciation.\n",
      "\n",
      "4. **Result from Financial Items:**\n",
      "   - **Interest Income:** Decreased from 37,542 KSEK in 2022 to 35,292 KSEK in 2023.\n",
      "   - **Interest Expenses:** These decreased significantly from -33,767 KSEK in 2022 to -20,866 KSEK in 2023, reducing the financial burden on the company.\n",
      "\n",
      "5. **Profit After Financial Items:** The loss improved from -85,115 KSEK in 2022 to -58,001 KSEK in 2023, aided by reduced interest expenses.\n",
      "\n",
      "6. **Tax on Profit for the Year:** For 2023, the tax on profit was 0 KSEK, while in 2022 it was -246 KSEK, indicating no taxable profit or that previous losses offset current tax liabilities.\n",
      "\n",
      "7. **Net Profit for the Year:** The final profit or loss after all expenses, including financial items and taxes, was a net loss of -58,001 KSEK in 2023, an improvement compared to the net loss of -85,362 KSEK in 2022.\n",
      "\n",
      "### Summary:\n",
      "The Consolidated Income Statement illustrates that the company experienced growth in net sales and improved its operating and net losses in 2023 compared to 2022. The increase in total operating income, coupled with reduced external costs and significantly lower interest expenses, led to a narrower net loss for the year. However, the company still operates at a substantial loss, highlighting ongoing challenges in achieving profitability. \n",
      "\n",
      "Additionally, it is important to note that the consolidated income statement includes the financial results of the parent company and all its subsidiaries, with adjustments made to align with the group's accounting policies. Intra-group transactions are eliminated to ensure that only transactions with external parties are reflected in the consolidated results. The reporting currency for the consolidated income statement is Swedish Krona, and foreign subsidiaries' income statement items are translated using the average annual exchange rate.\n",
      "📊 Context: User profile: name: Alice, occupation: history teacher, interests: ['ancient civilizations'] | Relevant past conversations (5 entries) | Recent history (20 messages)\n",
      "📋 Full Metadata: {\n",
      "  \"agent_type\": \"rag_agent\",\n",
      "  \"hits_count\": 3,\n",
      "  \"sources\": [\n",
      "    \"Artificial Solutions International AB_2023_SustainabilityReport.pdf\",\n",
      "    \"Artificial Solutions International AB_2023_SustainabilityReport.pdf\",\n",
      "    \"Artificial Solutions International AB_2023_SustainabilityReport.pdf\"\n",
      "  ],\n",
      "  \"modalities\": [\n",
      "    \"text\",\n",
      "    \"text\",\n",
      "    \"text\"\n",
      "  ],\n",
      "  \"memory_updated\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from graph.workflow import create_agentic_system, run_workflow\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Example Usage\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangGraph Multi-Agent System with Wikipedia ===\")\n",
    "    \n",
    "    # Create the system\n",
    "    system = create_agentic_system(user_id=\"alice123\", thread_id=\"langgraph_session\")\n",
    "    \n",
    "    # Test messages that will trigger different behaviors\n",
    "    test_messages = [\n",
    "        #\"Hello, I'm Alice, a history teacher interested in ancient civilizations\",\n",
    "        \"elaborate the consolidate income statement\",  # Should trigger Wikipedia search\n",
    "        #\"Search for machine learning papers in my documents\",  # RAG agent\n",
    "        #\"What do you know about quantum computing?\",  # Wikipedia + conversation\n",
    "        #\"Who was Albert Einstein?\",  # Wikipedia search\n",
    "        #\"How are you feeling today?\",  # Pure conversation\n",
    "        #\"Find images about neural networks in my files\",  # RAG agent\n",
    "        #\"Tell me about the history of artificial intelligence\",  # Wikipedia\n",
    "    ]\n",
    "    \n",
    "    for message in test_messages:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"👤 User: {message}\")\n",
    "        result = run_workflow(system, message)\n",
    "        \n",
    "        # Show detailed metadata\n",
    "        print(f\"📋 Full Metadata: {json.dumps(result['metadata'], indent=2)}\")\n",
    "        \n",
    "        if result['wikipedia_results']:\n",
    "            print(\"📚 Wikipedia Results:\")\n",
    "            for wiki in result['wikipedia_results']:\n",
    "                print(f\"   Query: {wiki['query']}\")\n",
    "                print(f\"   Result: {wiki['result'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "556f1611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 LangGraph Workflow: elaborate the consolidate income statement...\n",
      "📚 Memory Fetch Node: Loading context...\n",
      "✅ Memory loaded: 20 recent, 5 relevant, 3 facts\n",
      "🧠 Supervisor Node: Making routing decision...\n",
      "🎯 Supervisor decision: rag_agent\n",
      "🔍 RAG Agent Node: Processing document search...\n",
      "Loading indices from data/faiss_text.index and data/faiss_image.index with metadata from data/text_docs_info.pkl and data/image_docs_info.pkl\n",
      "[TEXT] 0.351 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_36)\n",
      "[TEXT] 0.347 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_38)\n",
      "[TEXT] 0.322 — Artificial Solutions International AB_2023_SustainabilityReport.pdf (ID: f6888c09-11e2-42d8-8541-85ba265985e4_txt_35)\n",
      "💾 Memory Update Node: Saving conversation...\n",
      "✅ Memory updated successfully\n",
      "🎉 LangGraph Workflow completed\n",
      "\n",
      "🤖 Agent (rag_agent): The consolidated income statement is a financial report that summarizes the financial performance of a parent company and its subsidiaries over a specific period, typically covering all operations up to the end of the fiscal year. For example, for Artificial Solutions, the consolidated income statement includes data for the fiscal years 1 January 2023 to 31 December 2023 and 1 January 2022 to 31 December 2022, with all amounts presented in thousand Swedish Krona (KSEK).\n",
      "\n",
      "### Key Components of the Consolidated Income Statement:\n",
      "\n",
      "1. **Operating Income:**\n",
      "   - **Net Sales:** This represents the revenue generated from the sale of goods or services. In 2023, net sales were 60,534 KSEK, an increase from 45,678 KSEK in 2022.\n",
      "   - **Capitalized Amount for Own Accounts:** This likely refers to development costs for intangible assets (like software) that are capitalized rather than expensed immediately. It was 20,944 KSEK in 2023, up from 13,178 KSEK in 2022.\n",
      "   - **Other Operating Income:** Income generated from non-primary business activities. It was -1,170 KSEK in 2023, indicating a loss compared to 5,842 KSEK in 2022.\n",
      "   - **Total Operating Income:** The sum of all operating revenues, which increased to 80,308 KSEK in 2023 from 64,698 KSEK in 2022.\n",
      "\n",
      "2. **Operating Expenses:**\n",
      "   - **Other External Costs:** Expenses paid to third parties for services or goods not directly related to personnel or depreciation, which decreased to -50,112 KSEK in 2023 from -55,438 KSEK in 2022.\n",
      "   - **Personnel Costs:** Wages, salaries, and other employee-related expenses, which increased slightly to -88,419 KSEK in 2023 from -85,460 KSEK in 2022.\n",
      "   - **Depreciation and Amortization:** Non-cash expenses that allocate the cost of tangible and intangible assets over their useful lives, which increased to -14,204 KSEK in 2023 from -12,689 KSEK in 2022.\n",
      "   - **Other Operating Expenses:** A minor expense of -2 KSEK was recorded in 2023, which was zero in 2022.\n",
      "\n",
      "3. **Operating Profit:** This reflects the profit or loss from core business operations before accounting for financial items and taxes. Artificial Solutions reported an operating loss of -72,430 KSEK in 2023, an improvement from -88,890 KSEK in 2022.\n",
      "\n",
      "4. **Result from Financial Items:**\n",
      "   - **Interest Income:** Income earned from interest on investments or loans, which decreased to 35,292 KSEK in 2023 from 37,542 KSEK in 2022.\n",
      "   - **Interest Expenses:** Costs incurred from borrowing money, which decreased to -20,866 KSEK in 2023 from -33,767 KSEK in 2022.\n",
      "\n",
      "5. **Profit After Financial Items:** This is the profit or loss after considering both operating and financial activities. The loss improved to -58,001 KSEK in 2023 from -85,115 KSEK in 2022.\n",
      "\n",
      "6. **Tax on Profit for the Year:** This shows the income tax expense or benefit. In 2023, there was no tax recorded (0 KSEK), while in 2022, there was a tax expense of -246 KSEK.\n",
      "\n",
      "7. **Net Profit for the Year:** This is the final figure representing the company's total profit or loss for the period. For Artificial Solutions, it was a net loss of -58,001 KSEK in 2023, a significant improvement from the net loss of -85,362 KSEK reported in 2022.\n",
      "\n",
      "### Consolidation Principles:\n",
      "The consolidated income statement is formed by combining the financial statements of the parent company and all its subsidiaries. It is essential to adjust the amounts recognized in the financial statements of subsidiaries to ensure consistency with the group's accounting policies. A key principle in consolidation is the elimination of intra-group transactions to prevent double-counting and present the group as a single economic entity. This includes removing any sales, purchases, or other transactions between companies within the group, as well as unrealized gains and losses.\n",
      "\n",
      "For foreign subsidiaries, their income statements are translated into the group's reporting currency (e.g., Swedish Krona) using the current method, with all items translated at the average annual exchange rate. Foreign currency transactions are recorded at the spot rate on the transaction date, and any gains or losses from these transactions are recorded directly in the income statement.\n",
      "\n",
      "In summary, the consolidated income statement for Artificial Solutions indicates that while the company is still operating at a loss, it has significantly reduced its net loss in 2023 compared to 2022, driven by increased net sales, reduced external costs, and lower interest expenses.\n",
      "📊 Context: User profile: name: Alice, occupation: history teacher, interests: ['ancient civilizations'] | Relevant past conversations (5 entries) | Recent history (20 messages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': \"The consolidated income statement is a financial report that summarizes the financial performance of a parent company and its subsidiaries over a specific period, typically covering all operations up to the end of the fiscal year. For example, for Artificial Solutions, the consolidated income statement includes data for the fiscal years 1 January 2023 to 31 December 2023 and 1 January 2022 to 31 December 2022, with all amounts presented in thousand Swedish Krona (KSEK).\\n\\n### Key Components of the Consolidated Income Statement:\\n\\n1. **Operating Income:**\\n   - **Net Sales:** This represents the revenue generated from the sale of goods or services. In 2023, net sales were 60,534 KSEK, an increase from 45,678 KSEK in 2022.\\n   - **Capitalized Amount for Own Accounts:** This likely refers to development costs for intangible assets (like software) that are capitalized rather than expensed immediately. It was 20,944 KSEK in 2023, up from 13,178 KSEK in 2022.\\n   - **Other Operating Income:** Income generated from non-primary business activities. It was -1,170 KSEK in 2023, indicating a loss compared to 5,842 KSEK in 2022.\\n   - **Total Operating Income:** The sum of all operating revenues, which increased to 80,308 KSEK in 2023 from 64,698 KSEK in 2022.\\n\\n2. **Operating Expenses:**\\n   - **Other External Costs:** Expenses paid to third parties for services or goods not directly related to personnel or depreciation, which decreased to -50,112 KSEK in 2023 from -55,438 KSEK in 2022.\\n   - **Personnel Costs:** Wages, salaries, and other employee-related expenses, which increased slightly to -88,419 KSEK in 2023 from -85,460 KSEK in 2022.\\n   - **Depreciation and Amortization:** Non-cash expenses that allocate the cost of tangible and intangible assets over their useful lives, which increased to -14,204 KSEK in 2023 from -12,689 KSEK in 2022.\\n   - **Other Operating Expenses:** A minor expense of -2 KSEK was recorded in 2023, which was zero in 2022.\\n\\n3. **Operating Profit:** This reflects the profit or loss from core business operations before accounting for financial items and taxes. Artificial Solutions reported an operating loss of -72,430 KSEK in 2023, an improvement from -88,890 KSEK in 2022.\\n\\n4. **Result from Financial Items:**\\n   - **Interest Income:** Income earned from interest on investments or loans, which decreased to 35,292 KSEK in 2023 from 37,542 KSEK in 2022.\\n   - **Interest Expenses:** Costs incurred from borrowing money, which decreased to -20,866 KSEK in 2023 from -33,767 KSEK in 2022.\\n\\n5. **Profit After Financial Items:** This is the profit or loss after considering both operating and financial activities. The loss improved to -58,001 KSEK in 2023 from -85,115 KSEK in 2022.\\n\\n6. **Tax on Profit for the Year:** This shows the income tax expense or benefit. In 2023, there was no tax recorded (0 KSEK), while in 2022, there was a tax expense of -246 KSEK.\\n\\n7. **Net Profit for the Year:** This is the final figure representing the company's total profit or loss for the period. For Artificial Solutions, it was a net loss of -58,001 KSEK in 2023, a significant improvement from the net loss of -85,362 KSEK reported in 2022.\\n\\n### Consolidation Principles:\\nThe consolidated income statement is formed by combining the financial statements of the parent company and all its subsidiaries. It is essential to adjust the amounts recognized in the financial statements of subsidiaries to ensure consistency with the group's accounting policies. A key principle in consolidation is the elimination of intra-group transactions to prevent double-counting and present the group as a single economic entity. This includes removing any sales, purchases, or other transactions between companies within the group, as well as unrealized gains and losses.\\n\\nFor foreign subsidiaries, their income statements are translated into the group's reporting currency (e.g., Swedish Krona) using the current method, with all items translated at the average annual exchange rate. Foreign currency transactions are recorded at the spot rate on the transaction date, and any gains or losses from these transactions are recorded directly in the income statement.\\n\\nIn summary, the consolidated income statement for Artificial Solutions indicates that while the company is still operating at a loss, it has significantly reduced its net loss in 2023 compared to 2022, driven by increased net sales, reduced external costs, and lower interest expenses.\",\n",
       " 'agent_used': 'rag_agent',\n",
       " 'metadata': {'agent_type': 'rag_agent',\n",
       "  'hits_count': 3,\n",
       "  'sources': ['Artificial Solutions International AB_2023_SustainabilityReport.pdf',\n",
       "   'Artificial Solutions International AB_2023_SustainabilityReport.pdf',\n",
       "   'Artificial Solutions International AB_2023_SustainabilityReport.pdf'],\n",
       "  'modalities': ['text', 'text', 'text'],\n",
       "  'memory_updated': True},\n",
       " 'tools_used': [],\n",
       " 'wikipedia_results': [],\n",
       " 'memory_context_summary': \"User profile: name: Alice, occupation: history teacher, interests: ['ancient civilizations'] | Relevant past conversations (5 entries) | Recent history (20 messages)\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_workflow(system, \"elaborate the consolidate income statement\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b305fee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 LangGraph Workflow: what is my name ...\n",
      "📚 Memory Fetch Node: Loading context...\n",
      "✅ Memory loaded: 20 recent, 5 relevant, 3 facts\n",
      "🧠 Supervisor Node: Making routing decision...\n",
      "🎯 Supervisor decision: chatbot\n",
      "💬 Chatbot Agent Node: Processing conversation...\n",
      "✅ Chatbot completed (tools: [])\n",
      "💾 Memory Update Node: Saving conversation...\n",
      "✅ Memory updated successfully\n",
      "🎉 LangGraph Workflow completed\n",
      "\n",
      "🤖 Agent (chatbot): Your name is Alice.\n",
      "📊 Context: User profile: name: Alice, occupation: history teacher, interests: ['ancient civilizations'] | Relevant past conversations (5 entries) | Recent history (20 messages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'Your name is Alice.',\n",
       " 'agent_used': 'chatbot',\n",
       " 'metadata': {'agent_type': 'chatbot',\n",
       "  'context_used': 20,\n",
       "  'user_facts_count': 3,\n",
       "  'tools_used': [],\n",
       "  'wikipedia_searches': 0,\n",
       "  'memory_updated': True},\n",
       " 'tools_used': [],\n",
       " 'wikipedia_results': [],\n",
       " 'memory_context_summary': \"User profile: name: Alice, occupation: history teacher, interests: ['ancient civilizations'] | Relevant past conversations (5 entries) | Recent history (20 messages)\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_workflow(system, \"what is my name \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98851b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FastAPI Backend for Multi-Agent AI System\n",
    "Integrates with the LangGraph workflow and provides WebSocket support\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import asyncio\n",
    "from typing import Dict, Any, List, Optional\n",
    "from datetime import datetime\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Depends\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastapi.responses import HTMLResponse, FileResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "\n",
    "from graph.workflow import LangGraphMultiAgentSystem, create_agentic_system\n",
    "\n",
    "# ===============================\n",
    "# Pydantic Models\n",
    "# ===============================\n",
    "\n",
    "class ChatMessage(BaseModel):\n",
    "    message: str = Field(..., min_length=1, max_length=4000)\n",
    "    user_id: str = Field(..., min_length=1)\n",
    "    thread_id: str = Field(default=\"default\")\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "    agent_used: str\n",
    "    tools_used: List[str]\n",
    "    wikipedia_results: List[Dict[str, Any]]\n",
    "    metadata: Dict[str, Any]\n",
    "    memory_context_summary: str\n",
    "    processing_time_ms: float\n",
    "    timestamp: str\n",
    "\n",
    "class WorkflowStatus(BaseModel):\n",
    "    step: str\n",
    "    status: str  # \"active\", \"completed\", \"error\"\n",
    "    timestamp: str\n",
    "    details: Optional[str] = None\n",
    "\n",
    "class SessionInfo(BaseModel):\n",
    "    session_id: str\n",
    "    user_id: str\n",
    "    thread_id: str\n",
    "    created_at: str\n",
    "    message_count: int\n",
    "    tools_used_count: int\n",
    "    active_agents: List[str]\n",
    "\n",
    "class HealthResponse(BaseModel):\n",
    "    status: str\n",
    "    version: str\n",
    "    agents_available: List[str]\n",
    "    memory_system: str\n",
    "    rag_system: str\n",
    "    timestamp: str\n",
    "\n",
    "# ===============================\n",
    "# Connection Manager for WebSockets\n",
    "# ===============================\n",
    "\n",
    "class ConnectionManager:\n",
    "    \"\"\"Manages WebSocket connections for real-time communication\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.active_connections: Dict[str, WebSocket] = {}\n",
    "        self.user_sessions: Dict[str, Dict[str, Any]] = {}\n",
    "    \n",
    "    async def connect(self, websocket: WebSocket, session_id: str, user_id: str):\n",
    "        await websocket.accept()\n",
    "        self.active_connections[session_id] = websocket\n",
    "        self.user_sessions[session_id] = {\n",
    "            \"user_id\": user_id,\n",
    "            \"connected_at\": datetime.now().isoformat(),\n",
    "            \"message_count\": 0,\n",
    "            \"tools_used\": 0\n",
    "        }\n",
    "        \n",
    "        # Send welcome message\n",
    "        await self.send_personal_message({\n",
    "            \"type\": \"connection_established\",\n",
    "            \"session_id\": session_id,\n",
    "            \"message\": \"Connected to Multi-Agent AI System\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }, session_id)\n",
    "    \n",
    "    def disconnect(self, session_id: str):\n",
    "        if session_id in self.active_connections:\n",
    "            del self.active_connections[session_id]\n",
    "        if session_id in self.user_sessions:\n",
    "            del self.user_sessions[session_id]\n",
    "    \n",
    "    async def send_personal_message(self, message: dict, session_id: str):\n",
    "        if session_id in self.active_connections:\n",
    "            try:\n",
    "                await self.active_connections[session_id].send_text(json.dumps(message))\n",
    "            except Exception as e:\n",
    "                print(f\"Error sending message to {session_id}: {e}\")\n",
    "                self.disconnect(session_id)\n",
    "    \n",
    "    async def send_workflow_update(self, session_id: str, step: str, status: str, details: str = None):\n",
    "        \"\"\"Send workflow step updates\"\"\"\n",
    "        await self.send_personal_message({\n",
    "            \"type\": \"workflow_update\",\n",
    "            \"step\": step,\n",
    "            \"status\": status,\n",
    "            \"details\": details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }, session_id)\n",
    "    \n",
    "    async def send_agent_highlight(self, session_id: str, agent_name: str):\n",
    "        \"\"\"Send agent highlighting update\"\"\"\n",
    "        await self.send_personal_message({\n",
    "            \"type\": \"agent_highlight\",\n",
    "            \"agent\": agent_name,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }, session_id)\n",
    "    \n",
    "    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\n",
    "        return self.user_sessions.get(session_id)\n",
    "\n",
    "# ===============================\n",
    "# Multi-Agent System Manager\n",
    "# ===============================\n",
    "\n",
    "class MultiAgentManager:\n",
    "    \"\"\"Manages multiple agent system instances\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.systems: Dict[str, EnhancedLangGraphMultiAgentSystem] = {}\n",
    "        self.connection_manager = ConnectionManager()\n",
    "    \n",
    "    def get_or_create_system(self, user_id: str, thread_id: str = \"default\") -> LangGraphMultiAgentSystem:\n",
    "        \"\"\"Get existing system or create new one\"\"\"\n",
    "        system_key = f\"{user_id}:{thread_id}\"\n",
    "        \n",
    "        if system_key not in self.systems:\n",
    "            self.systems[system_key] = create_agentic_system(\n",
    "                user_id=user_id, \n",
    "                thread_id=thread_id\n",
    "            )\n",
    "            print(f\"Created new system for {system_key}\")\n",
    "        \n",
    "        return self.systems[system_key]\n",
    "    \n",
    "    async def process_with_updates(\n",
    "        self, \n",
    "        system: LangGraphMultiAgentSystem, \n",
    "        message: str, \n",
    "        session_id: str\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Process message with real-time workflow updates\"\"\"\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Send workflow updates\n",
    "            await self.connection_manager.send_workflow_update(\n",
    "                session_id, \"memory\", \"active\", \"Loading conversation context...\"\n",
    "            )\n",
    "            \n",
    "            # Simulate workflow steps (in real implementation, these would be triggered by your actual workflow)\n",
    "            workflow_steps = [\n",
    "                (\"memory\", \"Memory context loaded\"),\n",
    "                (\"supervisor\", \"Analyzing request and routing...\"),\n",
    "                (\"agent\", \"Processing with selected agent...\"),\n",
    "                (\"update\", \"Updating memory system...\")\n",
    "            ]\n",
    "            \n",
    "            # Process the message\n",
    "            result = system.process(message)\n",
    "            \n",
    "            # Send agent highlight\n",
    "            await self.connection_manager.send_agent_highlight(\n",
    "                session_id, result.get(\"agent_used\", \"chatbot\")\n",
    "            )\n",
    "            \n",
    "            # Mark workflow steps as completed\n",
    "            for step, details in workflow_steps:\n",
    "                await self.connection_manager.send_workflow_update(\n",
    "                    session_id, step, \"completed\", details\n",
    "                )\n",
    "                await asyncio.sleep(0.3)  # Small delay for UI effect\n",
    "            \n",
    "            # Calculate processing time\n",
    "            processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000\n",
    "            \n",
    "            # Update session stats\n",
    "            if session_id in self.connection_manager.user_sessions:\n",
    "                session = self.connection_manager.user_sessions[session_id]\n",
    "                session[\"message_count\"] += 1\n",
    "                session[\"tools_used\"] += len(result.get(\"tools_used\", []))\n",
    "            \n",
    "            return {\n",
    "                **result,\n",
    "                \"processing_time_ms\": processing_time,\n",
    "                \"timestamp\": datetime.utcnow().isoformat()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Send error update\n",
    "            await self.connection_manager.send_workflow_update(\n",
    "                session_id, \"error\", \"error\", f\"Processing failed: {str(e)}\"\n",
    "            )\n",
    "            raise e\n",
    "\n",
    "# ===============================\n",
    "# FastAPI Application Setup\n",
    "# ===============================\n",
    "\n",
    "# Global managers\n",
    "agent_manager = MultiAgentManager()\n",
    "security = HTTPBearer(auto_error=False)\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Application lifespan management\"\"\"\n",
    "    print(\"🚀 Starting Multi-Agent AI System...\")\n",
    "    \n",
    "    # Initialize any required systems here\n",
    "    try:\n",
    "        # Test system creation\n",
    "        test_system = create_langgraph_system(\"system_test\", \"health_check\")\n",
    "        print(\"✅ Multi-agent system initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Multi-agent system initialization failed: {e}\")\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    print(\"🔄 Shutting down Multi-Agent AI System...\")\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Multi-Agent AI System\",\n",
    "    description=\"Professional AI system with LangGraph workflow and real-time UI\",\n",
    "    version=\"1.0.0\",\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# CORS middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Configure appropriately for production\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Authentication (Optional)\n",
    "# ===============================\n",
    "\n",
    "async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "    \"\"\"Optional authentication - customize as needed\"\"\"\n",
    "    if credentials is None:\n",
    "        return {\"user_id\": \"anonymous\", \"is_authenticated\": False}\n",
    "    \n",
    "    # Implement your authentication logic here\n",
    "    # For demo purposes, we'll extract user_id from token\n",
    "    try:\n",
    "        # This is a simple example - use proper JWT validation in production\n",
    "        user_id = credentials.credentials or \"anonymous\"\n",
    "        return {\"user_id\": user_id, \"is_authenticated\": True}\n",
    "    except Exception:\n",
    "        return {\"user_id\": \"anonymous\", \"is_authenticated\": False}\n",
    "\n",
    "# ===============================\n",
    "# REST API Endpoints\n",
    "# ===============================\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def get_dashboard():\n",
    "    \"\"\"Serve the main dashboard\"\"\"\n",
    "    # In production, serve your built frontend here\n",
    "    # For now, return a simple HTML that loads the UI\n",
    "    return \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Multi-Agent AI System</title>\n",
    "        <script>\n",
    "            // Redirect to the dashboard UI\n",
    "            window.location.href = '/dashboard';\n",
    "        </script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>Redirecting to dashboard...</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "@app.get(\"/health\", response_model=HealthResponse)\n",
    "async def health_check():\n",
    "    \"\"\"System health check\"\"\"\n",
    "    try:\n",
    "        # Test memory system\n",
    "        try:\n",
    "            from memory import MemoryAgent, MemoryConfig\n",
    "            memory_status = \"available\"\n",
    "        except ImportError:\n",
    "            memory_status = \"mock_system\"\n",
    "        \n",
    "        # Test RAG system\n",
    "        try:\n",
    "            from rag import RagAgent, rag_answer\n",
    "            rag_status = \"available\"\n",
    "        except ImportError:\n",
    "            rag_status = \"unavailable\"\n",
    "        \n",
    "        return HealthResponse(\n",
    "            status=\"healthy\",\n",
    "            version=\"1.0.0\",\n",
    "            agents_available=[\"supervisor\", \"chatbot\", \"rag_agent\", \"memory\"],\n",
    "            memory_system=memory_status,\n",
    "            rag_system=rag_status,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Health check failed: {str(e)}\")\n",
    "\n",
    "@app.post(\"/api/chat\", response_model=ChatResponse)\n",
    "async def chat_endpoint(\n",
    "    request: ChatMessage,\n",
    "    current_user: dict = Depends(get_current_user)\n",
    "):\n",
    "    \"\"\"REST endpoint for chat (alternative to WebSocket)\"\"\"\n",
    "    try:\n",
    "        # Get or create system\n",
    "        system = agent_manager.get_or_create_system(\n",
    "            user_id=request.user_id,\n",
    "            thread_id=request.thread_id\n",
    "        )\n",
    "        \n",
    "        # Process message\n",
    "        start_time = datetime.now()\n",
    "        result = system.process(request.message)\n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        return ChatResponse(\n",
    "            response=result[\"response\"],\n",
    "            agent_used=result[\"agent_used\"],\n",
    "            tools_used=result[\"tools_used\"],\n",
    "            wikipedia_results=result[\"wikipedia_results\"],\n",
    "            metadata=result[\"metadata\"],\n",
    "            memory_context_summary=result[\"memory_context_summary\"],\n",
    "            processing_time_ms=processing_time,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Chat processing failed: {str(e)}\")\n",
    "\n",
    "@app.get(\"/api/sessions/{session_id}\", response_model=SessionInfo)\n",
    "async def get_session_info(session_id: str):\n",
    "    \"\"\"Get session information\"\"\"\n",
    "    session = agent_manager.connection_manager.get_session_info(session_id)\n",
    "    if not session:\n",
    "        raise HTTPException(status_code=404, detail=\"Session not found\")\n",
    "    \n",
    "    return SessionInfo(\n",
    "        session_id=session_id,\n",
    "        user_id=session[\"user_id\"],\n",
    "        thread_id=\"default\",  # You might want to track this\n",
    "        created_at=session[\"connected_at\"],\n",
    "        message_count=session[\"message_count\"],\n",
    "        tools_used_count=session[\"tools_used\"],\n",
    "        active_agents=[\"supervisor\", \"chatbot\", \"rag_agent\", \"memory\"]\n",
    "    )\n",
    "\n",
    "@app.get(\"/api/agents\")\n",
    "async def get_available_agents():\n",
    "    \"\"\"Get information about available agents\"\"\"\n",
    "    return {\n",
    "        \"agents\": [\n",
    "            {\n",
    "                \"id\": \"supervisor\",\n",
    "                \"name\": \"Supervisor Agent\",\n",
    "                \"description\": \"Routes requests to appropriate agents based on context analysis\",\n",
    "                \"capabilities\": [\"routing\", \"decision_making\", \"context_analysis\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"chatbot\",\n",
    "                \"name\": \"Chatbot Agent\", \n",
    "                \"description\": \"Handles conversations with Wikipedia integration and memory context\",\n",
    "                \"capabilities\": [\"conversation\", \"wikipedia_search\", \"memory_context\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"rag_agent\",\n",
    "                \"name\": \"RAG Agent\",\n",
    "                \"description\": \"Searches and retrieves information from documents and knowledge base\",\n",
    "                \"capabilities\": [\"document_search\", \"knowledge_retrieval\", \"semantic_search\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"memory\",\n",
    "                \"name\": \"Memory System\",\n",
    "                \"description\": \"Manages context, user facts, and conversation history\",\n",
    "                \"capabilities\": [\"context_management\", \"user_profiling\", \"conversation_history\"]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# WebSocket Endpoint\n",
    "# ===============================\n",
    "\n",
    "@app.websocket(\"/ws/{session_id}\")\n",
    "async def websocket_endpoint(websocket: WebSocket, session_id: str, user_id: str = \"anonymous\"):\n",
    "    \"\"\"WebSocket endpoint for real-time communication\"\"\"\n",
    "    await agent_manager.connection_manager.connect(websocket, session_id, user_id)\n",
    "    \n",
    "    # Get or create AI system for this user\n",
    "    system = agent_manager.get_or_create_system(user_id=user_id, thread_id=session_id)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Receive message from client\n",
    "            data = await websocket.receive_text()\n",
    "            message_data = json.loads(data)\n",
    "            \n",
    "            if message_data.get(\"type\") == \"chat_message\":\n",
    "                user_message = message_data.get(\"message\", \"\")\n",
    "                \n",
    "                if user_message.strip():\n",
    "                    try:\n",
    "                        # Process message with real-time updates\n",
    "                        result = await agent_manager.process_with_updates(\n",
    "                            system, user_message, session_id\n",
    "                        )\n",
    "                        \n",
    "                        # Send response back to client\n",
    "                        await agent_manager.connection_manager.send_personal_message({\n",
    "                            \"type\": \"chat_response\",\n",
    "                            \"response\": result[\"response\"],\n",
    "                            \"agent_used\": result[\"agent_used\"],\n",
    "                            \"tools_used\": result[\"tools_used\"],\n",
    "                            \"wikipedia_results\": result[\"wikipedia_results\"],\n",
    "                            \"metadata\": result[\"metadata\"],\n",
    "                            \"memory_context_summary\": result[\"memory_context_summary\"],\n",
    "                            \"processing_time_ms\": result[\"processing_time_ms\"],\n",
    "                            \"timestamp\": result[\"timestamp\"]\n",
    "                        }, session_id)\n",
    "                        \n",
    "                        # Send metrics update\n",
    "                        session_info = agent_manager.connection_manager.get_session_info(session_id)\n",
    "                        if session_info:\n",
    "                            await agent_manager.connection_manager.send_personal_message({\n",
    "                                \"type\": \"metrics_update\",\n",
    "                                \"message_count\": session_info[\"message_count\"],\n",
    "                                \"tools_used\": session_info[\"tools_used\"]\n",
    "                            }, session_id)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        await agent_manager.connection_manager.send_personal_message({\n",
    "                            \"type\": \"error\",\n",
    "                            \"message\": f\"Processing failed: {str(e)}\",\n",
    "                            \"timestamp\": datetime.utcnow().isoformat()\n",
    "                        }, session_id)\n",
    "            \n",
    "            elif message_data.get(\"type\") == \"ping\":\n",
    "                # Health check ping\n",
    "                await agent_manager.connection_manager.send_personal_message({\n",
    "                    \"type\": \"pong\",\n",
    "                    \"timestamp\": datetime.utcnow().isoformat()\n",
    "                }, session_id)\n",
    "                \n",
    "    except WebSocketDisconnect:\n",
    "        agent_manager.connection_manager.disconnect(session_id)\n",
    "        print(f\"Client {session_id} disconnected\")\n",
    "    except Exception as e:\n",
    "        print(f\"WebSocket error for {session_id}: {e}\")\n",
    "        agent_manager.connection_manager.disconnect(session_id)\n",
    "\n",
    "# ===============================\n",
    "# Static Files (for serving the UI)\n",
    "# ===============================\n",
    "\n",
    "# Mount static files directory (create this directory and put your HTML/CSS/JS files there)\n",
    "# app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
    "\n",
    "@app.get(\"/dashboard\")\n",
    "async def serve_dashboard():\n",
    "    \"\"\"Serve the dashboard HTML\"\"\"\n",
    "    # Return the dashboard HTML - you can save the artifact HTML to a file and serve it\n",
    "    # For now, returning a simple redirect\n",
    "    dashboard_html = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Multi-Agent AI System</title>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; text-align: center; padding: 50px; }\n",
    "            .container { max-width: 600px; margin: 0 auto; }\n",
    "            .status { color: #10b981; font-weight: bold; }\n",
    "            .instructions { background: #f8f9fa; padding: 20px; border-radius: 8px; margin: 20px 0; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"container\">\n",
    "            <h1>🧠 Multi-Agent AI System</h1>\n",
    "            <p class=\"status\">✅ Backend Running Successfully</p>\n",
    "            \n",
    "            <div class=\"instructions\">\n",
    "                <h3>Integration Instructions:</h3>\n",
    "                <ol style=\"text-align: left;\">\n",
    "                    <li>Save the dashboard HTML artifact to <code>static/index.html</code></li>\n",
    "                    <li>Update the JavaScript to connect to WebSocket: <code>ws://localhost:8000/ws/{session_id}?user_id={user_id}</code></li>\n",
    "                    <li>Replace the mock system with WebSocket communication</li>\n",
    "                    <li>Uncomment the static files mounting in the FastAPI code</li>\n",
    "                </ol>\n",
    "            </div>\n",
    "            \n",
    "            <div>\n",
    "                <h3>Available Endpoints:</h3>\n",
    "                <ul style=\"text-align: left;\">\n",
    "                    <li><code>GET /health</code> - System health check</li>\n",
    "                    <li><code>POST /api/chat</code> - REST chat endpoint</li>\n",
    "                    <li><code>WS /ws/{session_id}</code> - WebSocket for real-time chat</li>\n",
    "                    <li><code>GET /api/agents</code> - Available agents info</li>\n",
    "                    <li><code>GET /api/sessions/{session_id}</code> - Session information</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return HTMLResponse(content=dashboard_html)\n",
    "\n",
    "# ===============================\n",
    "# Main Application Runner\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Starting Multi-Agent AI System with FastAPI...\")\n",
    "    print(\"📊 Dashboard will be available at: http://localhost:8000/dashboard\")\n",
    "    print(\"🔌 WebSocket endpoint: ws://localhost:8000/ws/{session_id}\")\n",
    "    print(\"⚡ REST API docs: http://localhost:8000/docs\")\n",
    "    \n",
    "    uvicorn.run(\n",
    "        \"main:app\",  # Replace with your actual module name\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        reload=True,  # Remove in production\n",
    "        log_level=\"info\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba12db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Will watch for changes in these directories: ['/media/dell-mcc/01DAD236571658001/agentic-ai/agentic-rag']\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "INFO:     Started reloader process [27143] using StatReload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Enhanced Multi-Agent AI System with REAL Workflow Tracking...\n",
      "📊 Dashboard: http://localhost:8000/dashboard\n",
      "🔌 WebSocket: ws://localhost:8000/ws/{session_id}\n",
      "⚡ API docs: http://localhost:8000/docs\n",
      "🎯 Real-time workflow progress enabled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Error loading ASGI app. Could not import module \"main\".\n",
      "INFO:     Stopping reloader process [27143]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FastAPI Backend with Real LangGraph Workflow Integration\n",
    "Hooks into actual workflow steps for live progress updates\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import asyncio\n",
    "from typing import Dict, Any, List, Optional, Callable\n",
    "from datetime import datetime\n",
    "from contextlib import asynccontextmanager\n",
    "from functools import wraps\n",
    "\n",
    "from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Depends\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastapi.responses import HTMLResponse, FileResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "\n",
    "# Import your existing multi-agent system\n",
    "\n",
    "from graph.workflow import LangGraphMultiAgentSystem, create_langgraph_system\n",
    "from graph.memory_nodes import enhanced_memory_fetch_node, enhanced_memory_update_node\n",
    "from graph.supervisor import enhanced_supervisor_node\n",
    "from graph.rag_node import enhanced_rag_agent_node\n",
    "from graph.chat_node import enhanced_chatbot_agent_node\n",
    "# ===============================\n",
    "# Workflow Progress Tracker\n",
    "# ===============================\n",
    "\n",
    "class WorkflowProgressTracker:\n",
    "    \"\"\"Tracks workflow progress and sends real-time updates\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.active_sessions: Dict[str, Dict[str, Any]] = {}\n",
    "        self.progress_callbacks: Dict[str, List[Callable]] = {}\n",
    "    \n",
    "    def register_session(self, session_id: str, websocket_manager):\n",
    "        \"\"\"Register a session for progress tracking\"\"\"\n",
    "        self.active_sessions[session_id] = {\n",
    "            \"websocket_manager\": websocket_manager,\n",
    "            \"current_step\": None,\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"steps_completed\": []\n",
    "        }\n",
    "    \n",
    "    def unregister_session(self, session_id: str):\n",
    "        \"\"\"Unregister a session\"\"\"\n",
    "        if session_id in self.active_sessions:\n",
    "            del self.active_sessions[session_id]\n",
    "        if session_id in self.progress_callbacks:\n",
    "            del self.progress_callbacks[session_id]\n",
    "    \n",
    "    async def update_step(self, session_id: str, step_name: str, status: str, details: str = None):\n",
    "        \"\"\"Update workflow step progress\"\"\"\n",
    "        if session_id not in self.active_sessions:\n",
    "            return\n",
    "        \n",
    "        session = self.active_sessions[session_id]\n",
    "        session[\"current_step\"] = step_name\n",
    "        \n",
    "        if status == \"completed\":\n",
    "            session[\"steps_completed\"].append(step_name)\n",
    "        \n",
    "        # Send WebSocket update\n",
    "        websocket_manager = session[\"websocket_manager\"]\n",
    "        await websocket_manager.send_workflow_update(session_id, step_name, status, details)\n",
    "        \n",
    "        print(f\"📊 Workflow Progress [{session_id}]: {step_name} -> {status}\")\n",
    "\n",
    "# Global progress tracker\n",
    "progress_tracker = WorkflowProgressTracker()\n",
    "\n",
    "# ===============================\n",
    "# Workflow Node Decorators\n",
    "# ===============================\n",
    "\n",
    "def track_workflow_step(step_name: str, description: str = None):\n",
    "    \"\"\"Decorator to track workflow step execution\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        async def async_wrapper(state: Dict, session_id: str = None) -> Dict:\n",
    "            # Start step\n",
    "            if session_id:\n",
    "                await progress_tracker.update_step(\n",
    "                    session_id, step_name, \"active\", description or f\"Executing {step_name}...\"\n",
    "                )\n",
    "            \n",
    "            try:\n",
    "                # Execute the actual function\n",
    "                if asyncio.iscoroutinefunction(func):\n",
    "                    result = await func(state)\n",
    "                else:\n",
    "                    result = func(state)\n",
    "                \n",
    "                # Complete step\n",
    "                if session_id:\n",
    "                    await progress_tracker.update_step(\n",
    "                        session_id, step_name, \"completed\", f\"{step_name.title()} completed successfully\"\n",
    "                    )\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Error step\n",
    "                if session_id:\n",
    "                    await progress_tracker.update_step(\n",
    "                        session_id, step_name, \"error\", f\"Error in {step_name}: {str(e)}\"\n",
    "                    )\n",
    "                raise e\n",
    "        \n",
    "        @wraps(func)\n",
    "        def sync_wrapper(state: Dict, session_id: str = None) -> Dict:\n",
    "            # For synchronous functions, we can't send real-time updates\n",
    "            # but we can still track progress\n",
    "            try:\n",
    "                result = func(state)\n",
    "                print(f\"✅ {step_name} completed (sync)\")\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {step_name} failed: {e}\")\n",
    "                raise e\n",
    "        \n",
    "        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper\n",
    "    return decorator\n",
    "\n",
    "# ===============================\n",
    "# Enhanced Multi-Agent System\n",
    "# ===============================\n",
    "\n",
    "class EnhancedLangGraphMultiAgentSystem(LangGraphMultiAgentSystem):\n",
    "    \"\"\"Enhanced multi-agent system with real-time progress tracking\"\"\"\n",
    "    \n",
    "    def __init__(self, user_id: str, thread_id: str = \"default\"):\n",
    "        super().__init__(user_id, thread_id)\n",
    "        self.session_id = None\n",
    "    \n",
    "    def set_session_id(self, session_id: str):\n",
    "        \"\"\"Set session ID for progress tracking\"\"\"\n",
    "        self.session_id = session_id\n",
    "    \n",
    "    async def process_with_tracking(self, user_message: str, session_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process message with real-time workflow tracking\"\"\"\n",
    "        \n",
    "        self.set_session_id(session_id)\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"user_message\": user_message,\n",
    "            \"user_id\": self.user_id,\n",
    "            \"thread_id\": self.thread_id,\n",
    "            \"messages\": [],\n",
    "            \"memory_context\": {},\n",
    "            \"selected_agent\": \"\",\n",
    "            \"agent_response\": \"\",\n",
    "            \"metadata\": {},\n",
    "            \"tools_used\": [],\n",
    "            \"wikipedia_results\": [],\n",
    "            \"session_id\": session_id  # Add session_id to state\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Execute workflow with tracking\n",
    "            final_state = await self._execute_workflow_with_tracking(initial_state)\n",
    "            \n",
    "            processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "            \n",
    "            return {\n",
    "                \"response\": final_state[\"agent_response\"],\n",
    "                \"agent_used\": final_state[\"selected_agent\"],\n",
    "                \"metadata\": final_state[\"metadata\"],\n",
    "                \"tools_used\": final_state[\"tools_used\"],\n",
    "                \"wikipedia_results\": final_state[\"wikipedia_results\"],\n",
    "                \"memory_context_summary\": final_state[\"memory_context\"].get(\"context_summary\", \"\"),\n",
    "                \"processing_time_ms\": processing_time,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"💥 Enhanced Workflow error: {e}\")\n",
    "            await progress_tracker.update_step(session_id, \"error\", \"error\", f\"Workflow failed: {str(e)}\")\n",
    "            \n",
    "            return {\n",
    "                \"response\": \"I encountered an error processing your request. Please try again.\",\n",
    "                \"agent_used\": \"error\",\n",
    "                \"metadata\": {\"error\": str(e)},\n",
    "                \"tools_used\": [],\n",
    "                \"wikipedia_results\": [],\n",
    "                \"memory_context_summary\": \"\",\n",
    "                \"processing_time_ms\": 0,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    async def _execute_workflow_with_tracking(self, initial_state: Dict) -> Dict:\n",
    "        \"\"\"Execute the workflow with step-by-step tracking\"\"\"\n",
    "        \n",
    "        session_id = initial_state[\"session_id\"]\n",
    "        \n",
    "        # Step 1: Memory Fetch\n",
    "        state = await self._tracked_memory_fetch(initial_state, session_id)\n",
    "        \n",
    "        # Step 2: Supervisor Decision\n",
    "        state = await self._tracked_supervisor(state, session_id)\n",
    "        \n",
    "        # Step 3: Agent Processing\n",
    "        if state[\"selected_agent\"] == \"rag_agent\":\n",
    "            state = await self._tracked_rag_agent(state, session_id)\n",
    "        else:\n",
    "            state = await self._tracked_chatbot_agent(state, session_id)\n",
    "        \n",
    "        # Step 4: Memory Update\n",
    "        state = await self._tracked_memory_update(state, session_id)\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    async def _tracked_memory_fetch(self, state: Dict, session_id: str) -> Dict:\n",
    "        \"\"\"Memory fetch with progress tracking\"\"\"\n",
    "        await progress_tracker.update_step(session_id, \"memory\", \"active\", \"Loading conversation context and user profile...\")\n",
    "        \n",
    "        try:\n",
    "            # Execute actual memory fetch\n",
    "            result = enhanced_memory_fetch_node(state)\n",
    "            \n",
    "            # Extract context info for detailed progress\n",
    "            memory_context = result.get(\"memory_context\", {})\n",
    "            details = []\n",
    "            \n",
    "            if memory_context.get(\"short_term\"):\n",
    "                details.append(f\"{len(memory_context['short_term'])} recent messages\")\n",
    "            if memory_context.get(\"long_term\"):\n",
    "                details.append(f\"{len(memory_context['long_term'])} relevant conversations\")\n",
    "            if memory_context.get(\"user_facts\"):\n",
    "                details.append(f\"{len(memory_context['user_facts'])} user facts\")\n",
    "            \n",
    "            detail_text = \"Loaded: \" + \", \".join(details) if details else \"Memory context loaded\"\n",
    "            \n",
    "            await progress_tracker.update_step(session_id, \"memory\", \"completed\", detail_text)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            await progress_tracker.update_step(session_id, \"memory\", \"error\", f\"Memory fetch failed: {str(e)}\")\n",
    "            raise e\n",
    "    \n",
    "    async def _tracked_supervisor(self, state: Dict, session_id: str) -> Dict:\n",
    "        \"\"\"Supervisor with progress tracking\"\"\"\n",
    "        await progress_tracker.update_step(session_id, \"supervisor\", \"active\", \"Analyzing request intent and routing to appropriate agent...\")\n",
    "        \n",
    "        try:\n",
    "            result = enhanced_supervisor_node(state)\n",
    "            selected_agent = result.get(\"selected_agent\", \"chatbot\")\n",
    "            \n",
    "            agent_names = {\n",
    "                \"rag_agent\": \"RAG Agent (Document Search)\",\n",
    "                \"chatbot\": \"Chatbot Agent (Conversation & Wikipedia)\"\n",
    "            }\n",
    "            \n",
    "            detail_text = f\"Routed to: {agent_names.get(selected_agent, selected_agent)}\"\n",
    "            await progress_tracker.update_step(session_id, \"supervisor\", \"completed\", detail_text)\n",
    "            \n",
    "            # Send agent highlight\n",
    "            session = progress_tracker.active_sessions.get(session_id)\n",
    "            if session:\n",
    "                websocket_manager = session[\"websocket_manager\"]\n",
    "                await websocket_manager.send_agent_highlight(session_id, selected_agent)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            await progress_tracker.update_step(session_id, \"supervisor\", \"error\", f\"Supervisor routing failed: {str(e)}\")\n",
    "            raise e\n",
    "    \n",
    "    async def _tracked_rag_agent(self, state: Dict, session_id: str) -> Dict:\n",
    "        \"\"\"RAG agent with progress tracking\"\"\"\n",
    "        await progress_tracker.update_step(session_id, \"agent\", \"active\", \"Searching documents and knowledge base...\")\n",
    "        \n",
    "        try:\n",
    "            result = enhanced_rag_agent_node(state)\n",
    "            \n",
    "            # Extract RAG-specific details\n",
    "            metadata = result.get(\"metadata\", {})\n",
    "            hits_count = metadata.get(\"hits_count\", 0)\n",
    "            sources = metadata.get(\"sources\", [])\n",
    "            \n",
    "            detail_text = f\"Found {hits_count} relevant documents\"\n",
    "            if sources:\n",
    "                detail_text += f\" from {len(set(sources))} sources\"\n",
    "            \n",
    "            await progress_tracker.update_step(session_id, \"agent\", \"completed\", detail_text)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            await progress_tracker.update_step(session_id, \"agent\", \"error\", f\"RAG agent failed: {str(e)}\")\n",
    "            raise e\n",
    "    \n",
    "    async def _tracked_chatbot_agent(self, state: Dict, session_id: str) -> Dict:\n",
    "        \"\"\"Chatbot agent with progress tracking\"\"\"\n",
    "        await progress_tracker.update_step(session_id, \"agent\", \"active\", \"Processing conversation with AI agent...\")\n",
    "        \n",
    "        try:\n",
    "            result = enhanced_chatbot_agent_node(state)\n",
    "            \n",
    "            # Extract chatbot-specific details\n",
    "            tools_used = result.get(\"tools_used\", [])\n",
    "            wikipedia_results = result.get(\"wikipedia_results\", [])\n",
    "            \n",
    "            details = [\"Response generated\"]\n",
    "            if tools_used:\n",
    "                details.append(f\"Used tools: {', '.join(tools_used)}\")\n",
    "            if wikipedia_results:\n",
    "                details.append(f\"Wikipedia searches: {len(wikipedia_results)}\")\n",
    "            \n",
    "            detail_text = \" | \".join(details)\n",
    "            await progress_tracker.update_step(session_id, \"agent\", \"completed\", detail_text)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            await progress_tracker.update_step(session_id, \"agent\", \"error\", f\"Chatbot agent failed: {str(e)}\")\n",
    "            raise e\n",
    "    \n",
    "    async def _tracked_memory_update(self, state: Dict, session_id: str) -> Dict:\n",
    "        \"\"\"Memory update with progress tracking\"\"\"\n",
    "        await progress_tracker.update_step(session_id, \"update\", \"active\", \"Saving conversation to memory system...\")\n",
    "        \n",
    "        try:\n",
    "            result = enhanced_memory_update_node(state)\n",
    "            \n",
    "            # Check if memory was actually updated\n",
    "            metadata = result.get(\"metadata\", {})\n",
    "            memory_updated = metadata.get(\"memory_updated\", False)\n",
    "            \n",
    "            detail_text = \"Conversation saved to memory\" if memory_updated else \"Memory update skipped\"\n",
    "            await progress_tracker.update_step(session_id, \"update\", \"completed\", detail_text)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            await progress_tracker.update_step(session_id, \"update\", \"error\", f\"Memory update failed: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "# ===============================\n",
    "# Enhanced Connection Manager\n",
    "# ===============================\n",
    "\n",
    "class EnhancedConnectionManager:\n",
    "    \"\"\"Enhanced connection manager with workflow integration\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.active_connections: Dict[str, WebSocket] = {}\n",
    "        self.user_sessions: Dict[str, Dict[str, Any]] = {}\n",
    "    \n",
    "    async def connect(self, websocket: WebSocket, session_id: str, user_id: str):\n",
    "        await websocket.accept()\n",
    "        self.active_connections[session_id] = websocket\n",
    "        self.user_sessions[session_id] = {\n",
    "            \"user_id\": user_id,\n",
    "            \"connected_at\": datetime.now().isoformat(),\n",
    "            \"message_count\": 0,\n",
    "            \"tools_used\": 0\n",
    "        }\n",
    "        \n",
    "        # Register with progress tracker\n",
    "        progress_tracker.register_session(session_id, self)\n",
    "        \n",
    "        # Send welcome message\n",
    "        await self.send_personal_message({\n",
    "            \"type\": \"connection_established\",\n",
    "            \"session_id\": session_id,\n",
    "            \"message\": \"Connected to Multi-Agent AI System with real-time workflow tracking\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }, session_id)\n",
    "    \n",
    "    def disconnect(self, session_id: str):\n",
    "        if session_id in self.active_connections:\n",
    "            del self.active_connections[session_id]\n",
    "        if session_id in self.user_sessions:\n",
    "            del self.user_sessions[session_id]\n",
    "        \n",
    "        # Unregister from progress tracker\n",
    "        progress_tracker.unregister_session(session_id)\n",
    "    \n",
    "    async def send_personal_message(self, message: dict, session_id: str):\n",
    "        if session_id in self.active_connections:\n",
    "            try:\n",
    "                await self.active_connections[session_id].send_text(json.dumps(message))\n",
    "            except Exception as e:\n",
    "                print(f\"Error sending message to {session_id}: {e}\")\n",
    "                self.disconnect(session_id)\n",
    "    \n",
    "    async def send_workflow_update(self, session_id: str, step: str, status: str, details: str = None):\n",
    "        \"\"\"Send workflow step updates\"\"\"\n",
    "        await self.send_personal_message({\n",
    "            \"type\": \"workflow_update\",\n",
    "            \"step\": step,\n",
    "            \"status\": status,\n",
    "            \"details\": details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }, session_id)\n",
    "    \n",
    "    async def send_agent_highlight(self, session_id: str, agent_name: str):\n",
    "        \"\"\"Send agent highlighting update\"\"\"\n",
    "        await self.send_personal_message({\n",
    "            \"type\": \"agent_highlight\",\n",
    "            \"agent\": agent_name,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }, session_id)\n",
    "    \n",
    "    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\n",
    "        return self.user_sessions.get(session_id)\n",
    "\n",
    "# ===============================\n",
    "# Enhanced Multi-Agent Manager\n",
    "# ===============================\n",
    "\n",
    "class EnhancedMultiAgentManager:\n",
    "    \"\"\"Enhanced manager with real workflow integration\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.systems: Dict[str, EnhancedLangGraphMultiAgentSystem] = {}\n",
    "        self.connection_manager = EnhancedConnectionManager()\n",
    "    \n",
    "    def get_or_create_system(self, user_id: str, thread_id: str = \"default\") -> EnhancedLangGraphMultiAgentSystem:\n",
    "        \"\"\"Get existing system or create new enhanced one\"\"\"\n",
    "        system_key = f\"{user_id}:{thread_id}\"\n",
    "        \n",
    "        if system_key not in self.systems:\n",
    "            # Create enhanced system instead of regular one\n",
    "            base_system = create_langgraph_system(user_id=user_id, thread_id=thread_id)\n",
    "            \n",
    "            # Convert to enhanced system (copy attributes)\n",
    "            enhanced_system = EnhancedLangGraphMultiAgentSystem(user_id=user_id, thread_id=thread_id)\n",
    "            enhanced_system.workflow = base_system.workflow\n",
    "            \n",
    "            self.systems[system_key] = enhanced_system\n",
    "            print(f\"Created enhanced system for {system_key}\")\n",
    "        \n",
    "        return self.systems[system_key]\n",
    "    \n",
    "    async def process_with_real_workflow(\n",
    "        self, \n",
    "        system: EnhancedLangGraphMultiAgentSystem, \n",
    "        message: str, \n",
    "        session_id: str\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Process message using real workflow with tracking\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Use the enhanced processing method\n",
    "            result = await system.process_with_tracking(message, session_id)\n",
    "            \n",
    "            # Update session stats\n",
    "            if session_id in self.connection_manager.user_sessions:\n",
    "                session = self.connection_manager.user_sessions[session_id]\n",
    "                session[\"message_count\"] += 1\n",
    "                session[\"tools_used\"] += len(result.get(\"tools_used\", []))\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            await progress_tracker.update_step(session_id, \"error\", \"error\", f\"Processing failed: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "# ===============================\n",
    "# FastAPI Application Setup\n",
    "# ===============================\n",
    "\n",
    "# Global enhanced manager\n",
    "enhanced_agent_manager = EnhancedMultiAgentManager()\n",
    "security = HTTPBearer(auto_error=False)\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Application lifespan management\"\"\"\n",
    "    print(\"🚀 Starting Enhanced Multi-Agent AI System...\")\n",
    "    \n",
    "    try:\n",
    "        # Test enhanced system creation\n",
    "        test_system = enhanced_agent_manager.get_or_create_system(\"system_test\", \"health_check\")\n",
    "        print(\"✅ Enhanced multi-agent system initialized successfully\")\n",
    "        print(\"📊 Real-time workflow tracking enabled\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Enhanced system initialization failed: {e}\")\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    print(\"🔄 Shutting down Enhanced Multi-Agent AI System...\")\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Enhanced Multi-Agent AI System\",\n",
    "    description=\"Professional AI system with real-time LangGraph workflow tracking\",\n",
    "    version=\"2.0.0\",\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# CORS middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Authentication\n",
    "# ===============================\n",
    "\n",
    "async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "    \"\"\"Optional authentication\"\"\"\n",
    "    if credentials is None:\n",
    "        return {\"user_id\": \"anonymous\", \"is_authenticated\": False}\n",
    "    \n",
    "    try:\n",
    "        user_id = credentials.credentials or \"anonymous\"\n",
    "        return {\"user_id\": user_id, \"is_authenticated\": True}\n",
    "    except Exception:\n",
    "        return {\"user_id\": \"anonymous\", \"is_authenticated\": False}\n",
    "\n",
    "# ===============================\n",
    "# Enhanced API Endpoints\n",
    "# ===============================\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def enhanced_health_check():\n",
    "    \"\"\"Enhanced health check with workflow status\"\"\"\n",
    "    try:\n",
    "        # Test workflow components\n",
    "        workflow_status = {\n",
    "            \"memory_fetch\": \"available\",\n",
    "            \"supervisor\": \"available\", \n",
    "            \"rag_agent\": \"checking...\",\n",
    "            \"chatbot_agent\": \"available\",\n",
    "            \"memory_update\": \"available\"\n",
    "        }\n",
    "        \n",
    "        # Test memory system\n",
    "        try:\n",
    "            from memory.mem_agent import MemoryAgent\n",
    "            from memory.mem_config import MemoryConfig\n",
    "            workflow_status[\"memory_system\"] = \"available\"\n",
    "        except ImportError:\n",
    "            workflow_status[\"memory_system\"] = \"mock_system\"\n",
    "        \n",
    "        # Test RAG system\n",
    "        try:\n",
    "            from rag_agent.ragagent import RagAgent, rag_answer\n",
    "            workflow_status[\"rag_agent\"] = \"available\"\n",
    "        except ImportError:\n",
    "            workflow_status[\"rag_agent\"] = \"unavailable\"\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"healthy\",\n",
    "            \"version\": \"2.0.0\",\n",
    "            \"workflow_tracking\": \"enabled\",\n",
    "            \"active_sessions\": len(progress_tracker.active_sessions),\n",
    "            \"workflow_status\": workflow_status,\n",
    "            \"agents_available\": [\"supervisor\", \"chatbot\", \"rag_agent\", \"memory\"],\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Enhanced health check failed: {str(e)}\")\n",
    "\n",
    "@app.post(\"/api/chat\")\n",
    "async def enhanced_chat_endpoint(request: dict, current_user: dict = Depends(get_current_user)):\n",
    "    \"\"\"Enhanced REST endpoint with workflow tracking\"\"\"\n",
    "    try:\n",
    "        user_message = request.get(\"message\", \"\")\n",
    "        user_id = request.get(\"user_id\", current_user[\"user_id\"])\n",
    "        thread_id = request.get(\"thread_id\", \"default\")\n",
    "        \n",
    "        # Generate session ID for tracking\n",
    "        session_id = f\"rest_{uuid.uuid4().hex[:8]}\"\n",
    "        \n",
    "        # Get or create enhanced system\n",
    "        system = enhanced_agent_manager.get_or_create_system(user_id=user_id, thread_id=thread_id)\n",
    "        \n",
    "        # Process with real workflow tracking\n",
    "        result = await enhanced_agent_manager.process_with_real_workflow(system, user_message, session_id)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Enhanced chat processing failed: {str(e)}\")\n",
    "\n",
    "# ===============================\n",
    "# Enhanced WebSocket Endpoint\n",
    "# ===============================\n",
    "\n",
    "@app.websocket(\"/ws/{session_id}\")\n",
    "async def enhanced_websocket_endpoint(websocket: WebSocket, session_id: str, user_id: str = \"anonymous\"):\n",
    "    \"\"\"Enhanced WebSocket with real workflow tracking\"\"\"\n",
    "    await enhanced_agent_manager.connection_manager.connect(websocket, session_id, user_id)\n",
    "    \n",
    "    # Get or create enhanced AI system\n",
    "    system = enhanced_agent_manager.get_or_create_system(user_id=user_id, thread_id=session_id)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Receive message from client\n",
    "            data = await websocket.receive_text()\n",
    "            message_data = json.loads(data)\n",
    "            \n",
    "            if message_data.get(\"type\") == \"chat_message\":\n",
    "                user_message = message_data.get(\"message\", \"\")\n",
    "                \n",
    "                if user_message.strip():\n",
    "                    try:\n",
    "                        # Process message with REAL workflow tracking\n",
    "                        result = await enhanced_agent_manager.process_with_real_workflow(\n",
    "                            system, user_message, session_id\n",
    "                        )\n",
    "                        \n",
    "                        # Send response back to client\n",
    "                        await enhanced_agent_manager.connection_manager.send_personal_message({\n",
    "                            \"type\": \"chat_response\",\n",
    "                            \"response\": result[\"response\"],\n",
    "                            \"agent_used\": result[\"agent_used\"],\n",
    "                            \"tools_used\": result[\"tools_used\"],\n",
    "                            \"wikipedia_results\": result[\"wikipedia_results\"],\n",
    "                            \"metadata\": result[\"metadata\"],\n",
    "                            \"memory_context_summary\": result[\"memory_context_summary\"],\n",
    "                            \"processing_time_ms\": result[\"processing_time_ms\"],\n",
    "                            \"timestamp\": result[\"timestamp\"]\n",
    "                        }, session_id)\n",
    "                        \n",
    "                        # Send metrics update\n",
    "                        session_info = enhanced_agent_manager.connection_manager.get_session_info(session_id)\n",
    "                        if session_info:\n",
    "                            await enhanced_agent_manager.connection_manager.send_personal_message({\n",
    "                                \"type\": \"metrics_update\",\n",
    "                                \"message_count\": session_info[\"message_count\"],\n",
    "                                \"tools_used\": session_info[\"tools_used\"]\n",
    "                            }, session_id)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        await enhanced_agent_manager.connection_manager.send_personal_message({\n",
    "                            \"type\": \"error\",\n",
    "                            \"message\": f\"Processing failed: {str(e)}\",\n",
    "                            \"timestamp\": datetime.now().isoformat()\n",
    "                        }, session_id)\n",
    "            \n",
    "            elif message_data.get(\"type\") == \"ping\":\n",
    "                await enhanced_agent_manager.connection_manager.send_personal_message({\n",
    "                    \"type\": \"pong\",\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }, session_id)\n",
    "                \n",
    "    except WebSocketDisconnect:\n",
    "        enhanced_agent_manager.connection_manager.disconnect(session_id)\n",
    "        print(f\"Enhanced client {session_id} disconnected\")\n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced WebSocket error for {session_id}: {e}\")\n",
    "        enhanced_agent_manager.connection_manager.disconnect(session_id)\n",
    "\n",
    "# ===============================\n",
    "# Dashboard Routes\n",
    "# ===============================\n",
    "\n",
    "@app.get(\"/dashboard\", response_class=HTMLResponse)\n",
    "async def serve_enhanced_dashboard():\n",
    "    \"\"\"Serve the enhanced dashboard\"\"\"\n",
    "    try:\n",
    "        return FileResponse(\"static/index.html\")\n",
    "    except FileNotFoundError:\n",
    "        return HTMLResponse(\"\"\"\n",
    "        <h1>Enhanced Multi-Agent AI System</h1>\n",
    "        <p>✅ Backend is running with REAL workflow tracking!</p>\n",
    "        <p>📋 Save the integrated dashboard as static/index.html</p>\n",
    "        <p>🔗 WebSocket: ws://localhost:8000/ws/{session_id}</p>\n",
    "        <p>📊 Active sessions: {}</p>\n",
    "        \"\"\".format(len(progress_tracker.active_sessions)))\n",
    "\n",
    "@app.get(\"/api/workflow/status/{session_id}\")\n",
    "async def get_workflow_status(session_id: str):\n",
    "    \"\"\"Get current workflow status for a session\"\"\"\n",
    "    if session_id not in progress_tracker.active_sessions:\n",
    "        raise HTTPException(status_code=404, detail=\"Session not found\")\n",
    "    \n",
    "    session = progress_tracker.active_sessions[session_id]\n",
    "    return {\n",
    "        \"session_id\": session_id,\n",
    "        \"current_step\": session.get(\"current_step\"),\n",
    "        \"steps_completed\": session.get(\"steps_completed\", []),\n",
    "        \"start_time\": session.get(\"start_time\"),\n",
    "        \"active\": True\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# Static Files\n",
    "# ===============================\n",
    "\n",
    "# Uncomment when you have the static directory\n",
    "# app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
    "\n",
    "# ===============================\n",
    "# Main Application Runner\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Starting Enhanced Multi-Agent AI System with REAL Workflow Tracking...\")\n",
    "    print(\"📊 Dashboard: http://localhost:8000/dashboard\")\n",
    "    print(\"🔌 WebSocket: ws://localhost:8000/ws/{session_id}\")\n",
    "    print(\"⚡ API docs: http://localhost:8000/docs\")\n",
    "    print(\"🎯 Real-time workflow progress enabled!\")\n",
    "    \n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        reload=True,\n",
    "        log_level=\"info\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9db78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
